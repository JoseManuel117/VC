{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import math \n",
    "import numpy as np\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde cámara, detección con yolov8 y modelo nano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 56.5ms\n",
      "Speed: 2.5ms preprocess, 56.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.3\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 46.5ms\n",
      "Speed: 2.0ms preprocess, 46.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.26\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 46.0ms\n",
      "Speed: 1.0ms preprocess, 46.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 57.0ms\n",
      "Speed: 1.5ms preprocess, 57.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.33\n",
      "Class name --> clock\n",
      "0: 480x640 1 clock, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 44.0ms\n",
      "Speed: 1.5ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.31\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 44.5ms\n",
      "Speed: 1.5ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.28\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.31\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 58.5ms\n",
      "Speed: 1.5ms preprocess, 58.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 44.0ms\n",
      "Speed: 0.5ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 43.5ms\n",
      "Speed: 0.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.3\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.26\n",
      "Class name --> clock\n",
      "0: 480x640 1 clock, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.33\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 45.0ms\n",
      "Speed: 0.5ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 47.0ms\n",
      "Speed: 0.5ms preprocess, 47.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.32\n",
      "Class name --> clock\n",
      "0: 480x640 1 clock, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 50.0ms\n",
      "Speed: 1.0ms preprocess, 50.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.26\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.31\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.28\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 46.5ms\n",
      "Speed: 0.5ms preprocess, 46.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.36\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 43.5ms\n",
      "Speed: 0.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.33\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.38\n",
      "Class name --> clock\n",
      "0: 480x640 1 clock, 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 44.0ms\n",
      "Speed: 1.5ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.29\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.3\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 0.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.4\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.36\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.5\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.55\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 person, 1 bicycle, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.51\n",
      "Class name --> person\n",
      "Confidence ---> 0.33\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 person, 1 bicycle, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.52\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> clock\n",
      "0: 480x640 1 person, 1 clock, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.6\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 2.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.53\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.5ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.65\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 person, 1 bicycle, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.64\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 49.0ms\n",
      "Speed: 1.0ms preprocess, 49.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.59\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.59\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.59\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.6\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 0.5ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.62\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.52\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.5\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.41\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.42\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.5\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.45\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.3\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.35\n",
      "Class name --> clock\n",
      "0: 480x640 1 clock, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.43\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.46\n",
      "Class name --> keyboard\n",
      "Confidence ---> 0.31\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 1 keyboard, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.3\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 51.0ms\n",
      "Speed: 1.0ms preprocess, 51.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.54\n",
      "Class name --> clock\n",
      "0: 480x640 1 clock, 45.0ms\n",
      "Speed: 1.5ms preprocess, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.38\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.48\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.5ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.59\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> clock\n",
      "0: 480x640 1 person, 1 clock, 43.0ms\n",
      "Speed: 1.5ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.46\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.53\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.57\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 0.5ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.58\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.0ms\n",
      "Speed: 0.5ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> bicycle\n",
      "Confidence ---> 0.27\n",
      "Class name --> clock\n",
      "0: 480x640 1 person, 1 bicycle, 1 clock, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.55\n",
      "Class name --> clock\n",
      "0: 480x640 1 person, 1 clock, 44.5ms\n",
      "Speed: 1.5ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.67\n",
      "Class name --> clock\n",
      "Confidence ---> 0.65\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 1 clock, 44.5ms\n",
      "Speed: 0.5ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.68\n",
      "Class name --> person\n",
      "Confidence ---> 0.4\n",
      "Class name --> clock\n",
      "0: 480x640 1 person, 1 clock, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.75\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.75\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> clock\n",
      "Confidence ---> 0.27\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 1 clock, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> clock\n",
      "0: 480x640 1 person, 1 clock, 43.0ms\n",
      "Speed: 0.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Confidence ---> 0.42\n",
      "Class name --> bicycle\n",
      "Confidence ---> 0.34\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 1 bicycle, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 0.5ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 46.5ms\n",
      "Speed: 1.0ms preprocess, 46.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 0.5ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.0ms\n",
      "Speed: 1.5ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.67\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.5ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.61\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.8\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> clock\n",
      "0: 480x640 1 person, 1 clock, 44.0ms\n",
      "Speed: 1.5ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.8\n",
      "Class name --> person\n",
      "Confidence ---> 0.75\n",
      "Class name --> clock\n",
      "0: 480x640 1 person, 1 clock, 44.0ms\n",
      "Speed: 0.5ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.8\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> clock\n",
      "0: 480x640 1 person, 1 clock, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> clock\n",
      "0: 480x640 1 person, 1 clock, 43.5ms\n",
      "Speed: 0.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> clock\n",
      "0: 480x640 1 person, 1 clock, 44.0ms\n",
      "Speed: 0.5ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.64\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> clock\n",
      "0: 480x640 1 person, 1 clock, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.34\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.63\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 0.5ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> chair\n",
      "0: 480x640 1 person, 1 chair, 44.0ms\n",
      "Speed: 0.5ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.5ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 0.5ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.5ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.5ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 46.5ms\n",
      "Speed: 1.0ms preprocess, 46.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> chair\n",
      "0: 480x640 1 person, 1 chair, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 46.5ms\n",
      "Speed: 0.5ms preprocess, 46.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> chair\n",
      "0: 480x640 1 person, 1 chair, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.96\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.96\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 47.5ms\n",
      "Speed: 1.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 0.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> chair\n",
      "0: 480x640 2 persons, 1 chair, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 0.5ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 0.5ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.44\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.0ms\n",
      "Speed: 1.5ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 0.5ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 48.5ms\n",
      "Speed: 1.0ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 46.0ms\n",
      "Speed: 1.0ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 52.0ms\n",
      "Speed: 1.0ms preprocess, 52.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 46.0ms\n",
      "Speed: 1.0ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 0.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 0.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 0.5ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 49.0ms\n",
      "Speed: 2.5ms preprocess, 49.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 48.5ms\n",
      "Speed: 1.0ms preprocess, 48.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.49\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.29\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.44\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.3\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 44.0ms\n",
      "Speed: 1.5ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.4\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.28\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 44.0ms\n",
      "Speed: 0.5ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.44\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.28\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.33\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.35\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.26\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.3\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.28\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.45\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 47.0ms\n",
      "Speed: 2.0ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.33\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.29\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.67\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.42\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.38\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 41.5ms\n",
      "Speed: 1.5ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.3\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.45\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.49\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.42\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 52.0ms\n",
      "Speed: 1.0ms preprocess, 52.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.4\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 43.0ms\n",
      "Speed: 0.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.26\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.5ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.35\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.65\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.36\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.27\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 3 cell phones, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.26\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 43.5ms\n",
      "Speed: 1.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.46\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.31\n",
      "Class name --> remote\n",
      "0: 480x640 1 person, 1 remote, 1 cell phone, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 51.0ms\n",
      "Speed: 1.0ms preprocess, 51.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.33\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 0.5ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.58\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.5ms\n",
      "Speed: 1.5ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.0ms\n",
      "Speed: 0.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.0ms\n",
      "Speed: 0.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.69\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.64\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.67\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.5ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 0.5ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.68\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.68\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 46.0ms\n",
      "Speed: 1.0ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.69\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.69\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.0ms\n",
      "Speed: 1.5ms preprocess, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.78\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 61.0ms\n",
      "Speed: 0.5ms preprocess, 61.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 0.5ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.5ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 0.5ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 48.5ms\n",
      "Speed: 1.0ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 55.0ms\n",
      "Speed: 1.0ms preprocess, 55.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.0ms\n",
      "Speed: 0.5ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 0.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.5ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.4\n",
      "Class name --> cup\n",
      "Confidence ---> 0.28\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 46.0ms\n",
      "Speed: 1.5ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.5ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 0.5ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 0.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 0.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 47.5ms\n",
      "Speed: 1.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 0.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 61.5ms\n",
      "Speed: 1.0ms preprocess, 61.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 46.5ms\n",
      "Speed: 0.5ms preprocess, 46.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.0ms\n",
      "Speed: 1.5ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.8\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 48.5ms\n",
      "Speed: 1.5ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 0.5ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.8\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 46.0ms\n",
      "Speed: 1.0ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 0.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.8\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.78\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "Confidence ---> 0.52\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.78\n",
      "Class name --> person\n",
      "Confidence ---> 0.77\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.57\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.0ms\n",
      "Speed: 0.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 41.5ms\n",
      "Speed: 1.5ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.5ms\n",
      "Speed: 0.5ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 2.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 49.5ms\n",
      "Speed: 1.5ms preprocess, 49.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 46.0ms\n",
      "Speed: 1.0ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.27\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.46\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 48.5ms\n",
      "Speed: 1.0ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 0.5ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.46\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.6\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 42.0ms\n",
      "Speed: 1.5ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.53\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 47.0ms\n",
      "Speed: 1.0ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.53\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.45\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 46.0ms\n",
      "Speed: 1.0ms preprocess, 46.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 44.5ms\n",
      "Speed: 0.5ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> cup\n",
      "Confidence ---> 0.35\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 49.5ms\n",
      "Speed: 1.0ms preprocess, 49.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.6\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 47.5ms\n",
      "Speed: 1.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.33\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.52\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.35\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.61\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.35\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.62\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.41\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.64\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.38\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.33\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.4\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.4\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.27\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 43.0ms\n",
      "Speed: 1.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.33\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.29\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 46.5ms\n",
      "Speed: 1.0ms preprocess, 46.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 60.5ms\n",
      "Speed: 1.0ms preprocess, 60.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.28\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.49\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.52\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.54\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.71\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 1 cell phone, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.6\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.7\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.59\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.79\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.61\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.85\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.81\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 46.5ms\n",
      "Speed: 0.5ms preprocess, 46.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "Confidence ---> 0.78\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 46.0ms\n",
      "Speed: 1.0ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.8\n",
      "Class name --> person\n",
      "Confidence ---> 0.6\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.26\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 44.0ms\n",
      "Speed: 0.5ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "Confidence ---> 0.58\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.31\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.27\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 3 cell phones, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Confidence ---> 0.46\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.71\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.69\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.75\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.7\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 51.0ms\n",
      "Speed: 1.0ms preprocess, 51.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.68\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.51\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.6\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 44.0ms\n",
      "Speed: 0.5ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.54\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.6\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.58\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.57\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.59\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.74\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.67\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 44.0ms\n",
      "Speed: 1.5ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.77\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.77\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 49.5ms\n",
      "Speed: 1.0ms preprocess, 49.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 0.5ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "Confidence ---> 0.44\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 41.0ms\n",
      "Speed: 1.5ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.42\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 0.5ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.53\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.64\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.4\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 0.5ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.53\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.7\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.58\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 47.0ms\n",
      "Speed: 3.0ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.42\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.29\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.46\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.26\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.3\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 41.0ms\n",
      "Speed: 0.5ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.4\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.45\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.45\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.28\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.48\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.29\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 42.0ms\n",
      "Speed: 0.5ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.45\n",
      "Class name --> cup\n",
      "Confidence ---> 0.31\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.39\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.55\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.36\n",
      "Class name --> cup\n",
      "Confidence ---> 0.27\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cup, 2 cell phones, 48.5ms\n",
      "Speed: 1.5ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.33\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.31\n",
      "Class name --> cup\n",
      "Confidence ---> 0.29\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cup, 2 cell phones, 43.0ms\n",
      "Speed: 0.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.3\n",
      "Class name --> cup\n",
      "Confidence ---> 0.26\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cup, 2 cell phones, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.48\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.4\n",
      "Class name --> cup\n",
      "Confidence ---> 0.37\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cup, 2 cell phones, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.45\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.35\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.37\n",
      "Class name --> cup\n",
      "Confidence ---> 0.26\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.26\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cup, 3 cell phones, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.29\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 46.5ms\n",
      "Speed: 2.0ms preprocess, 46.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 57.5ms\n",
      "Speed: 1.0ms preprocess, 57.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 46.5ms\n",
      "Speed: 1.0ms preprocess, 46.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.5ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.33\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.42\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 60.0ms\n",
      "Speed: 1.0ms preprocess, 60.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 48.5ms\n",
      "Speed: 1.0ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 0.5ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.29\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 60.0ms\n",
      "Speed: 1.0ms preprocess, 60.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 57.5ms\n",
      "Speed: 1.0ms preprocess, 57.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.29\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 52.0ms\n",
      "Speed: 1.0ms preprocess, 52.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.4\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 45.0ms\n",
      "Speed: 0.5ms preprocess, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# Carga del modelo\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Nombre de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "\n",
    "# Captura desde lawebcam\n",
    "vid = cv2.VideoCapture(0)\n",
    "  \n",
    "while(True):      \n",
    "    # fotograma a fotograma\n",
    "    ret, img = vid.read()\n",
    "  \n",
    "    # si hay imagen válida\n",
    "    if ret:  \n",
    "        # Perform inference on an image\n",
    "        results = model(img, stream=True)\n",
    "        \n",
    "        # Para cada detección\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                # Contenedor\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "                \n",
    "                # Confianza\n",
    "                confidence = math.ceil((box.conf[0]*100))/100\n",
    "                print(\"Confidence --->\",confidence)\n",
    "\n",
    "                # Clase\n",
    "                cls = int(box.cls[0])\n",
    "                print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "                # Convierte identificador numérico de clase a un color RGB\n",
    "                escala = int((cls / len(classNames)) * 255 * 3)\n",
    "                if escala >= 255*2:\n",
    "                    R = 255\n",
    "                    G = 255\n",
    "                    B = escala - 255*2\n",
    "                else:\n",
    "                    if escala >= 255:\n",
    "                        R = 255\n",
    "                        G = escala - 255\n",
    "                        B = 0\n",
    "                    else:\n",
    "                        R = escala\n",
    "                        G = 0\n",
    "                        B = 0\n",
    "\n",
    "                # Dibuja el contenedor y clase\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "                cv2.putText(img, classNames[cls] , [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "        # Muestra fotograma\n",
    "        cv2.imshow('Vid', img)\n",
    "    \n",
    "    # Detenemos pulsado ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "  \n",
    "# Libera el objeto de captura\n",
    "vid.release()\n",
    "# Destruye ventanas\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconocimiento de caracteres tras instalar pytesseract y tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 4 cars, 1 truck, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ganma\\AppData\\Local\\Temp\\ipykernel_22312\\1027782351.py:33: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box = np.int0(box)  # Redondea los valores a enteros\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 1 car, 8.5ms\n",
      "Speed: 1.5ms preprocess, 8.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 1 truck, 7.5ms\n",
      "Speed: 1.5ms preprocess, 7.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 6.0ms\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 6.0ms\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 1 truck, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 1 truck, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Para cada detección\\nfor r in results:\\n    boxes = r.boxes\\n\\n    for box in boxes:\\n        x1, y1, x2, y2 = box.xyxy[0]\\n        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\\n        \\n        # [ ... Tu código para dibujar el contenedor y clase ... ]\\n\\n        # Identificación de la matrícula para coches\\n        if classNames[int(box.cls[0])] == \"car\":\\n            # Seleccionar la parte inferior del coche para buscar la matrícula\\n            car_img = img[y1:y2, x1:x2]\\n\\n            # Aplica la función encontrar_matricula a la imagen del coche\\n            encontrar_matricula(car_img)\\n\\n            # Dibujar el resultado de vuelta en la imagen original\\n            img[y1:y2, x1:x2] = car_img\\n\\n# Muestra la imagen\\ncv2.imshow(\\'Imagen Detectada\\', img)\\ncv2.waitKey(0)\\ncv2.destroyAllWindows()\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga del modelo\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Nombre de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "folder_path = \"./images/\"\n",
    "\n",
    "image_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "reader = easyocr.Reader(['es'])\n",
    "\n",
    "def encontrar_matricula(car_img):\n",
    "    gray = cv2.cvtColor(car_img, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edged = cv2.Canny(blur, 30, 150)\n",
    "\n",
    "    contours, _ = cv2.findContours(edged, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for cnt in contours:\n",
    "        rect = cv2.minAreaRect(cnt)  # Obtiene el rectángulo rotado más pequeño\n",
    "        box = cv2.boxPoints(rect)  # Obtiene los cuatro puntos del rectángulo\n",
    "        box = np.int0(box)  # Redondea los valores a enteros\n",
    "\n",
    "        # Calcular el área del rectángulo para filtrar contornos pequeños\n",
    "        area = cv2.contourArea(box)\n",
    "        if 800 < area < 5000:\n",
    "            # Extraer la porción de la imagen dentro del rectángulo\n",
    "            mask = np.zeros_like(gray)\n",
    "            cv2.drawContours(mask, [box], 0, 255, -1)\n",
    "            masked = cv2.bitwise_and(car_img, car_img, mask=mask)\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            crop = masked[y:y+h, x:x+w]\n",
    "\n",
    "            # Convertir recorte a formato RGB para EasyOCR\n",
    "            crop_rgb = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Aplicar OCR usando EasyOCR\n",
    "            results = reader.readtext(crop_rgb)\n",
    "\n",
    "            # Si se detecta texto, dibujar el rectángulo y agregar texto en la esquina inferior izquierda del rectángulo\n",
    "            if results:\n",
    "                # Agregar texto de matrícula en la esquina inferior izquierda del rectángulo\n",
    "                matricula_text = results[0][-2]\n",
    "                if len(matricula_text) >= 2:\n",
    "                    cv2.drawContours(car_img, [box], 0, (0, 255, 0), 3)\n",
    "                    return matricula_text\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "\"\"\"\n",
    "def encontrar_matricula(car_img):\n",
    "    # Convertir a escala de grises\n",
    "    gray = cv2.cvtColor(car_img, cv2.COLOR_BGR2GRAY)\n",
    "    # Aplicar desenfoque para reducir el ruido\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    # Detector de bordes\n",
    "    edged = cv2.Canny(blur, 30, 150)\n",
    "\n",
    "    # Buscar contornos\n",
    "    contours, _ = cv2.findContours(edged, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    rectangulos = []\n",
    "\n",
    "    for cnt in contours:\n",
    "        # Aproximar el contorno a un polígono\n",
    "        epsilon = 0.05 * cv2.arcLength(cnt, True)  # Aumenta el valor de epsilon para una forma más general\n",
    "        approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "        \n",
    "        # Considerar contornos con un número de vértices cercano a 4 (por ejemplo, de 4 a 10)\n",
    "        if 4 <= len(approx) <= 10:  \n",
    "            area = cv2.contourArea(cnt)\n",
    "            # Ajustar los umbrales de área para incluir un rango más amplio\n",
    "            if 50 < area < 20000:  # Los umbrales dependen del tamaño esperado de los rectángulos\n",
    "                x, y, w, h = cv2.boundingRect(approx)\n",
    "                aspect_ratio = w / float(h)\n",
    "\n",
    "                # Considerar un rango más amplio de proporciones de aspecto\n",
    "                if 0.2 < aspect_ratio < 5:\n",
    "                    rectangulos.append(cnt)\n",
    "                    # Dibujar el contorno en la imagen recortada, no en la original\n",
    "                    cv2.drawContours(car_img, [cnt], 0, (0, 255, 0), 3)\n",
    "\"\"\"\n",
    "\n",
    "for image_file in image_files:\n",
    "    # Lee la imagen desde la carpeta\n",
    "    img = cv2.imread(os.path.join(folder_path, image_file))\n",
    "    target_size = (800, 600)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    \n",
    "    # Perform inference on an image\n",
    "    results = model(img)\n",
    "\n",
    "    # Para cada detección\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Identificación de la matrícula para coches\n",
    "            if classNames[int(box.cls[0])] == \"car\":\n",
    "                # Dibuja un rectángulo negro alrededor del coche\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 0), 2)\n",
    "                # Calcular la mitad de la altura del recuadro\n",
    "                mitad_altura = (y2 - y1) // 2\n",
    "\n",
    "                # Recortar solo la mitad inferior del recuadro\n",
    "                mitad_inferior_car_img = img[y1 + mitad_altura:y2, x1:x2]\n",
    "\n",
    "                # Pasar esta mitad inferior a la función encontrar_matricula\n",
    "                matricula_text= encontrar_matricula(mitad_inferior_car_img)\n",
    "\n",
    "                cv2.putText(img, \"car \" + matricula_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "                \n",
    "\n",
    "        # Muestra la imagen con las detecciones\n",
    "        cv2.imshow('Image', img)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "# Cierra la ventana al finalizar\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\"\"\"\n",
    "# Para cada detección\n",
    "for r in results:\n",
    "    boxes = r.boxes\n",
    "\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0]\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "        \n",
    "        # [ ... Tu código para dibujar el contenedor y clase ... ]\n",
    "\n",
    "        # Identificación de la matrícula para coches\n",
    "        if classNames[int(box.cls[0])] == \"car\":\n",
    "            # Seleccionar la parte inferior del coche para buscar la matrícula\n",
    "            car_img = img[y1:y2, x1:x2]\n",
    "\n",
    "            # Aplica la función encontrar_matricula a la imagen del coche\n",
    "            encontrar_matricula(car_img)\n",
    "\n",
    "            # Dibujar el resultado de vuelta en la imagen original\n",
    "            img[y1:y2, x1:x2] = car_img\n",
    "\n",
    "# Muestra la imagen\n",
    "cv2.imshow('Imagen Detectada', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eng', 'osd']\n",
      "Hasta el infinito y mas alla\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tesseract\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# Previamente debes descargar los ejecutables\n",
    "# Si la ruta de Tesseract no está en el PATH, ruta al ejecutable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract'\n",
    "\n",
    "# Lenguajes disponibles\n",
    "print(pytesseract.get_languages(config=''))\n",
    "\n",
    "#Cargo imagen y ocnvierto a RGB\n",
    "img = cv2.imread('toy.tif') \n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#Aplica reconocedor a imagen cargada\n",
    "print(pytesseract.image_to_string(img_rgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconocimiento decaracteres tras instalar easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([[49, 85], [617, 85], [617, 147], [49, 147]], 'Hasta el infinito y más allá', 0.6744627670805162)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Carga del modelo de lengua\n",
    "reader = easyocr.Reader(['es']) \n",
    "\n",
    "#Reconocimiento de una imagen\n",
    "result = reader.readtext('toy.tif')\n",
    "print(result)\n",
    "\n",
    "#Con restricción de caracteres reconocibles\n",
    "#result = reader.readtext('toy.tif', allowlist ='0123456789')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 22 11:03:52 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 546.12                 Driver Version: 546.12       CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080 Ti   WDDM  | 00000000:2B:00.0  On |                  N/A |\n",
      "| 30%   45C    P3              78W / 350W |   3091MiB / 12288MiB |      9%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1664    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A      7568    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     10036    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A     16724    C+G   ...air\\Corsair iCUE5 Software\\iCUE.exe    N/A      |\n",
      "|    0   N/A  N/A     17932    C+G   ...sair iCUE5 Software\\QmlRenderer.exe    N/A      |\n",
      "|    0   N/A  N/A     19188    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     20564    C+G   ...56.0_x64__zpdnekdrzrea0\\Spotify.exe    N/A      |\n",
      "|    0   N/A  N/A     25984    C+G   ...6.0_x64__cv1g1gvanyjgm\\WhatsApp.exe    N/A      |\n",
      "|    0   N/A  N/A     28832    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe    N/A      |\n",
      "|    0   N/A  N/A     29004    C+G   ...al\\Discord\\app-1.0.9024\\Discord.exe    N/A      |\n",
      "|    0   N/A  N/A     31552    C+G   ...on\\wallpaper_engine\\wallpaper64.exe    N/A      |\n",
      "|    0   N/A  N/A     35036      C   ...nma\\anaconda3\\envs\\VC_P5\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     38872    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     40532    C+G   ...B\\system_tray\\lghub_system_tray.exe    N/A      |\n",
      "|    0   N/A  N/A     40808    C+G   ...al\\Discord\\app-1.0.9024\\Discord.exe    N/A      |\n",
      "|    0   N/A  N/A     42104    C+G   ...Programs\\Microsoft VS Code\\Code.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "nw = min([os.cpu_count()])\n",
    "print(nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Ultralytics YOLOv8.0.215 🚀 Python-3.11.5 torch-2.1.1 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12288MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=C:/Users/ganma/Documents/Datasets/datasetMaestro/data.yaml, epochs=300, patience=25, batch=-1, imgsz=416, save=True, save_period=-1, cache=False, device=0, workers=12, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train4\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLOv8n summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=416\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA GeForce RTX 3080 Ti) 12.00G total, 1.81G reserved, 1.42G allocated, 8.77G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "     3011043       3.462         1.980         15.17         9.834        (1, 3, 416, 416)                    list\n",
      "     3011043       6.924         1.860          13.5         9.833        (2, 3, 416, 416)                    list\n",
      "     3011043       13.85         1.864         12.67         9.668        (4, 3, 416, 416)                    list\n",
      "     3011043        27.7         2.127         12.33         9.833        (8, 3, 416, 416)                    list\n",
      "     3011043       55.39         2.408         13.83          13.5       (16, 3, 416, 416)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 97 for CUDA:0 8.46G/12.00G (70%) ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\ganma\\Documents\\Datasets\\datasetMaestro\\train\\labels.cache... 18528 images, 18 backgrounds, 0 corrupt: 100%|██████████| 18528/18528 [00:00<?, ?it/s]\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x0000023FA0823740>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ganma\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"c:\\Users\\ganma\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1436, in _shutdown_workers\n",
      "    if self._persistent_workers or self._workers_status[worker_id]:\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\ganma\\Documents\\Datasets\\datasetMaestro\\valid\\labels.cache... 1765 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1765/1765 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train4\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0007578125), 63 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 12 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train4\u001b[0m\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/300      7.03G      3.258      3.403      3.451          2        416: 100%|██████████| 192/192 [00:39<00:00,  4.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.771      0.695      0.733      0.331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/300      7.01G       1.65      1.242      1.733          2        416: 100%|██████████| 192/192 [00:33<00:00,  5.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.906      0.809      0.869      0.461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/300      7.01G      1.439     0.9297      1.491          2        416: 100%|██████████| 192/192 [00:32<00:00,  5.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.904      0.842       0.89       0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/300         7G      1.351     0.7752      1.401          1        416: 100%|██████████| 192/192 [00:32<00:00,  5.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840       0.96      0.899      0.938      0.581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/300         7G      1.282     0.6868       1.34          1        416: 100%|██████████| 192/192 [00:32<00:00,  5.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.977      0.906      0.951      0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/300         7G      1.241     0.6441       1.31          1        416: 100%|██████████| 192/192 [00:32<00:00,  5.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.972      0.907      0.951      0.633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/300         7G      1.217     0.6195      1.296          1        416: 100%|██████████| 192/192 [00:34<00:00,  5.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.959      0.914      0.942      0.634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/300         7G      1.208     0.6033      1.281          3        416: 100%|██████████| 192/192 [00:35<00:00,  5.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.977      0.927      0.957      0.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/300         7G      1.181     0.5853      1.267          0        416: 100%|██████████| 192/192 [00:34<00:00,  5.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.974      0.925      0.958      0.653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/300         7G      1.184      0.576      1.262          1        416: 100%|██████████| 192/192 [00:34<00:00,  5.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.978       0.93      0.962      0.654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/300         7G      1.165     0.5665      1.255          0        416: 100%|██████████| 192/192 [00:34<00:00,  5.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.985      0.926      0.961      0.659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/300         7G      1.159     0.5464      1.246          1        416: 100%|██████████| 192/192 [00:34<00:00,  5.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.979      0.924      0.954       0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/300         7G      1.153     0.5436      1.248          1        416: 100%|██████████| 192/192 [00:33<00:00,  5.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840       0.97      0.937      0.964      0.673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/300         7G      1.153     0.5383       1.24          2        416: 100%|██████████| 192/192 [00:33<00:00,  5.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.983      0.931      0.961      0.652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/300         7G      1.139      0.532      1.236          2        416: 100%|██████████| 192/192 [00:34<00:00,  5.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840       0.98      0.942      0.965      0.673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/300         7G      1.135     0.5249      1.235          1        416: 100%|██████████| 192/192 [00:33<00:00,  5.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.982      0.944      0.963      0.677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/300         7G      1.126     0.5176      1.231          3        416: 100%|██████████| 192/192 [00:34<00:00,  5.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.986      0.936      0.965       0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/300         7G       1.13     0.5241      1.229          4        416: 100%|██████████| 192/192 [00:32<00:00,  5.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.983      0.935      0.965      0.685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/300         7G      1.122     0.5139      1.227          1        416: 100%|██████████| 192/192 [00:33<00:00,  5.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.978      0.941      0.968      0.685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/300         7G      1.121      0.512       1.22          1        416: 100%|██████████| 192/192 [00:32<00:00,  5.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.982      0.939      0.966      0.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/300         7G      1.108     0.5052      1.214          0        416: 100%|██████████| 192/192 [00:33<00:00,  5.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.983      0.943       0.97      0.686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/300         7G      1.103      0.503      1.214          1        416: 100%|██████████| 192/192 [00:32<00:00,  5.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.944       0.97      0.685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/300         7G      1.107      0.501      1.218          1        416: 100%|██████████| 192/192 [00:33<00:00,  5.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.945       0.97       0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/300         7G      1.095     0.4984      1.201          0        416: 100%|██████████| 192/192 [00:32<00:00,  5.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.982      0.941      0.971       0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/300         7G      1.096     0.4978      1.212          1        416: 100%|██████████| 192/192 [00:33<00:00,  5.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.945      0.972      0.695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/300         7G      1.109     0.4963      1.228          1        416: 100%|██████████| 192/192 [00:32<00:00,  5.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.987       0.94      0.971       0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/300         7G      1.114     0.5044      1.211          1        416: 100%|██████████| 192/192 [00:33<00:00,  5.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.983      0.943      0.972      0.684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/300         7G      1.088     0.4865      1.195          0        416: 100%|██████████| 192/192 [00:32<00:00,  5.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.982      0.944      0.971      0.694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/300         7G      1.094     0.4859       1.21          1        416: 100%|██████████| 192/192 [00:33<00:00,  5.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.941      0.969      0.693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/300         7G      1.099     0.4932      1.209          2        416: 100%|██████████| 192/192 [00:32<00:00,  5.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.943      0.974      0.696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/300         7G       1.08     0.4801        1.2          1        416: 100%|██████████| 192/192 [00:32<00:00,  5.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.985      0.945      0.974      0.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/300         7G       1.08     0.4784      1.193          1        416: 100%|██████████| 192/192 [00:32<00:00,  5.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.946      0.973      0.698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/300         7G      1.079     0.4761      1.196          3        416: 100%|██████████| 192/192 [00:35<00:00,  5.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840       0.98      0.949      0.975      0.694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/300         7G      1.075      0.477      1.195          1        416: 100%|██████████| 192/192 [00:33<00:00,  5.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.983      0.944      0.974      0.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/300         7G      1.075     0.4722        1.2          2        416: 100%|██████████| 192/192 [00:35<00:00,  5.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.983      0.948      0.975      0.689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/300         7G      1.073     0.4735      1.194          2        416: 100%|██████████| 192/192 [00:33<00:00,  5.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.987      0.942      0.974      0.703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/300         7G      1.065     0.4675      1.188          2        416: 100%|██████████| 192/192 [00:34<00:00,  5.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.948      0.974      0.698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/300         7G      1.064     0.4693      1.193          1        416: 100%|██████████| 192/192 [00:32<00:00,  5.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.948      0.973      0.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/300         7G       1.07     0.4959      1.201          1        416: 100%|██████████| 192/192 [00:33<00:00,  5.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.982      0.945      0.973      0.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/300         7G      1.062     0.4638      1.189          3        416: 100%|██████████| 192/192 [00:34<00:00,  5.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.985      0.946      0.974      0.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/300         7G      1.067     0.4638        1.2          1        416: 100%|██████████| 192/192 [00:33<00:00,  5.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.989      0.944      0.976        0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/300         7G      1.059     0.4662       1.19          2        416: 100%|██████████| 192/192 [00:32<00:00,  5.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.987      0.948      0.975      0.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/300         7G      1.059     0.4646      1.193          1        416: 100%|██████████| 192/192 [00:35<00:00,  5.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.988      0.946      0.976      0.702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/300         7G      1.056     0.4589      1.185          1        416: 100%|██████████| 192/192 [00:34<00:00,  5.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.987      0.942      0.974      0.702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/300         7G      1.052     0.4573      1.182          1        416: 100%|██████████| 192/192 [00:35<00:00,  5.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.949      0.975      0.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/300         7G       1.05     0.4566      1.182          1        416: 100%|██████████| 192/192 [00:34<00:00,  5.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.987      0.946      0.975      0.703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/300         7G      1.055     0.4573      1.185          1        416: 100%|██████████| 192/192 [00:35<00:00,  5.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.985      0.953      0.978      0.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/300         7G      1.057     0.4566      1.187          1        416: 100%|██████████| 192/192 [00:34<00:00,  5.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.978      0.955      0.977      0.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/300         7G      1.042     0.4541      1.178          1        416: 100%|██████████| 192/192 [00:35<00:00,  5.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.979      0.953      0.976      0.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/300         7G      1.039     0.4524      1.169          0        416: 100%|██████████| 192/192 [00:35<00:00,  5.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.981      0.954      0.976      0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/300         7G      1.053     0.4545      1.183          1        416: 100%|██████████| 192/192 [00:35<00:00,  5.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.955      0.976      0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/300         7G      1.036     0.4488      1.176          3        416: 100%|██████████| 192/192 [00:34<00:00,  5.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.982      0.955      0.976      0.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/300         7G      1.043     0.4499      1.176          3        416: 100%|██████████| 192/192 [00:35<00:00,  5.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840       0.98      0.953      0.978      0.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/300         7G       1.05     0.4535      1.178          1        416: 100%|██████████| 192/192 [00:34<00:00,  5.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.987      0.949      0.976      0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/300         7G       1.04     0.4465      1.176          1        416: 100%|██████████| 192/192 [00:35<00:00,  5.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.989      0.948      0.978      0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/300         7G      1.039     0.4474      1.174          4        416: 100%|██████████| 192/192 [00:34<00:00,  5.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.987      0.951      0.977      0.707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/300         7G       1.04      0.449      1.175          2        416: 100%|██████████| 192/192 [00:34<00:00,  5.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:08<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.986      0.956       0.98      0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/300         7G      1.031     0.4441      1.171          2        416: 100%|██████████| 192/192 [00:34<00:00,  5.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:08<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.989      0.951      0.979      0.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/300         7G      1.036     0.4465      1.174          1        416: 100%|██████████| 192/192 [00:34<00:00,  5.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:08<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.982      0.957      0.979      0.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/300         7G      1.035     0.4431      1.168          4        416: 100%|██████████| 192/192 [00:34<00:00,  5.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.986      0.954      0.979      0.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/300         7G      1.036     0.4469      1.168          1        416: 100%|██████████| 192/192 [00:34<00:00,  5.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.983      0.956       0.98      0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/300         7G      1.042     0.4428      1.174          1        416: 100%|██████████| 192/192 [00:34<00:00,  5.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.988      0.952      0.979      0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/300         7G      1.032     0.4428      1.176          2        416: 100%|██████████| 192/192 [00:34<00:00,  5.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.955       0.98      0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/300         7G      1.022     0.4397      1.165          1        416: 100%|██████████| 192/192 [00:34<00:00,  5.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.985      0.955      0.979      0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/300         7G      1.032     0.4403      1.173          1        416: 100%|██████████| 192/192 [00:35<00:00,  5.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:08<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.952      0.979      0.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/300         7G      1.018     0.4445      1.161          0        416: 100%|██████████| 192/192 [00:35<00:00,  5.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.985      0.953      0.979      0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/300         7G      1.027     0.4382      1.166          1        416: 100%|██████████| 192/192 [00:34<00:00,  5.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.955      0.979      0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/300         7G       1.02     0.4391      1.164          1        416: 100%|██████████| 192/192 [00:34<00:00,  5.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.982      0.956      0.979      0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/300         7G      1.025     0.4362      1.166          3        416: 100%|██████████| 192/192 [00:35<00:00,  5.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.953       0.98      0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/300         7G      1.019     0.4314      1.164          1        416: 100%|██████████| 192/192 [00:35<00:00,  5.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.952      0.978      0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/300         7G      1.018     0.4394      1.161          0        416: 100%|██████████| 192/192 [00:34<00:00,  5.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.982      0.955      0.979      0.707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/300         7G      1.015     0.4338      1.164          2        416: 100%|██████████| 192/192 [00:34<00:00,  5.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:08<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.978      0.959      0.979      0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/300         7G      1.031     0.4644      1.166          1        416: 100%|██████████| 192/192 [00:34<00:00,  5.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:08<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840       0.98      0.957      0.979      0.707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/300         7G      1.016     0.4317      1.161          2        416: 100%|██████████| 192/192 [00:34<00:00,  5.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.987       0.95      0.978      0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/300         7G      1.015     0.4306      1.162          2        416: 100%|██████████| 192/192 [00:34<00:00,  5.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840       0.98      0.956      0.977      0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/300         7G      1.009      0.432      1.158          2        416: 100%|██████████| 192/192 [00:35<00:00,  5.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.987       0.95      0.976      0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/300         7G      1.012     0.4292      1.157          1        416: 100%|██████████| 192/192 [00:34<00:00,  5.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.985      0.953      0.978       0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/300         7G      1.012       0.43      1.163          1        416: 100%|██████████| 192/192 [00:35<00:00,  5.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.986      0.953      0.978       0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/300         7G      1.012     0.4278       1.16          2        416: 100%|██████████| 192/192 [00:34<00:00,  5.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.985      0.953      0.978      0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/300         7G       1.01     0.4256      1.157          1        416: 100%|██████████| 192/192 [00:35<00:00,  5.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.985      0.953      0.978      0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/300         7G      1.013     0.4281      1.161          3        416: 100%|██████████| 192/192 [00:34<00:00,  5.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.981      0.957      0.978       0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/300         7G       1.01     0.4297      1.157          1        416: 100%|██████████| 192/192 [00:35<00:00,  5.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.978      0.959      0.978      0.709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/300         7G      1.008     0.4262      1.158          2        416: 100%|██████████| 192/192 [00:34<00:00,  5.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.981      0.958      0.978      0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/300         7G      1.007     0.4253      1.155          1        416: 100%|██████████| 192/192 [00:35<00:00,  5.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.979      0.959      0.978      0.712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/300         7G      1.008     0.4285      1.155          1        416: 100%|██████████| 192/192 [00:34<00:00,  5.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840       0.98      0.958      0.979      0.712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/300         7G      1.004     0.4225      1.158          2        416: 100%|██████████| 192/192 [00:35<00:00,  5.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.981      0.958      0.979      0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/300         7G      1.006     0.4267      1.156          3        416: 100%|██████████| 192/192 [00:34<00:00,  5.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.981      0.959      0.979      0.712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/300         7G     0.9989     0.4214      1.153          1        416: 100%|██████████| 192/192 [00:35<00:00,  5.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.982      0.959      0.979      0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/300         7G      1.004     0.4228      1.154          3        416: 100%|██████████| 192/192 [00:34<00:00,  5.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.983      0.958      0.979       0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/300         7G     0.9976     0.4215      1.152          1        416: 100%|██████████| 192/192 [00:34<00:00,  5.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.983      0.957      0.979      0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/300         7G      1.004      0.423      1.158          2        416: 100%|██████████| 192/192 [00:34<00:00,  5.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.983      0.958      0.979       0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/300         7G     0.9944     0.4182      1.149          2        416: 100%|██████████| 192/192 [00:35<00:00,  5.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.983      0.959      0.979      0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/300         7G     0.9948     0.4167      1.152          1        416: 100%|██████████| 192/192 [00:34<00:00,  5.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.982      0.959      0.979       0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/300         7G     0.9989     0.4209      1.159          1        416: 100%|██████████| 192/192 [00:35<00:00,  5.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.983      0.959      0.978      0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/300         7G     0.9913     0.4199       1.15          3        416: 100%|██████████| 192/192 [00:35<00:00,  5.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.983       0.96      0.978      0.712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/300         7G     0.9925     0.4172      1.149          1        416: 100%|██████████| 192/192 [00:35<00:00,  5.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.983       0.96      0.978      0.712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/300         7G     0.9942     0.4197      1.144          2        416: 100%|██████████| 192/192 [00:34<00:00,  5.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984       0.96      0.978       0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/300         7G     0.9991     0.4191      1.154          1        416: 100%|██████████| 192/192 [00:35<00:00,  5.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:08<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.983      0.959      0.978       0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/300         7G     0.9873     0.4165      1.147          2        416: 100%|██████████| 192/192 [00:34<00:00,  5.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.959      0.978       0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/300         7G      0.998     0.4171      1.163          1        416: 100%|██████████| 192/192 [00:35<00:00,  5.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.958      0.978       0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    101/300         7G     0.9894     0.4149      1.145          3        416: 100%|██████████| 192/192 [00:34<00:00,  5.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.958      0.978      0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    102/300         7G     0.9951     0.4162      1.148          3        416: 100%|██████████| 192/192 [00:35<00:00,  5.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.958      0.979       0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    103/300         7G     0.9887     0.4163      1.149          2        416: 100%|██████████| 192/192 [00:34<00:00,  5.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.958      0.979       0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    104/300         7G     0.9874     0.4182      1.147          1        416: 100%|██████████| 192/192 [00:35<00:00,  5.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.958      0.979       0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    105/300         7G     0.9883     0.4146      1.149          1        416: 100%|██████████| 192/192 [00:34<00:00,  5.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.958      0.979       0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    106/300         7G     0.9799     0.4126      1.146          1        416: 100%|██████████| 192/192 [00:35<00:00,  5.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.958      0.979       0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    107/300         7G     0.9852     0.4333      1.153          1        416: 100%|██████████| 192/192 [00:34<00:00,  5.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:08<00:00,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.957      0.979      0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    108/300         7G     0.9804      0.412      1.141          3        416: 100%|██████████| 192/192 [00:34<00:00,  5.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.957      0.979      0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    109/300         7G     0.9813     0.4125      1.142          4        416: 100%|██████████| 192/192 [00:34<00:00,  5.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.984      0.957      0.978      0.711\n",
      "Stopping training early as no improvement observed in last 25 epochs. Best results observed at epoch 84, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=25) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "109 epochs completed in 1.280 hours.\n",
      "Optimizer stripped from runs\\detect\\train4\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train4\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train4\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.215 🚀 Python-3.11.5 torch-2.1.1 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12288MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:09<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1765       1840      0.979      0.959      0.978      0.712\n",
      "Speed: 0.0ms preprocess, 0.4ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = YOLO(\"yolov8n.yaml\")\n",
    "# Train the model with adjusted settings\n",
    "results = model.train(data='C:/Users/ganma/Documents/Datasets/datasetMaestro/data.yaml', \n",
    "                        epochs=300, \n",
    "                        imgsz=416, \n",
    "                        plots=True,\n",
    "                        patience= 25,\n",
    "                        batch=-1,\n",
    "                        workers=12,\n",
    "                        device=0,\n",
    "                        )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.215 🚀 Python-3.11.5 torch-2.1.1 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12288MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 11, len(boxes) = 204. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "                   all        118        204      0.898      0.721      0.802      0.426\n",
      "Speed: 1.9ms preprocess, 4.6ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val\u001b[0m\n",
      "💡 Learn more at https://docs.ultralytics.com/modes/val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\ganma\\Downloads\\valid\\labels.cache... 118 images, 0 backgrounds, 0 corrupt: 100%|██████████| 118/118 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\ganma\\Downloads\\valid\\labels.cache... 118 images, 0 backgrounds, 0 corrupt: 100%|██████████| 118/118 [00:00<?, ?it/s]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/8 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  12%|█▎        | 1/8 [00:04<00:33,  4.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  25%|██▌       | 2/8 [00:05<00:13,  2.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  38%|███▊      | 3/8 [00:05<00:06,  1.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|█████     | 4/8 [00:05<00:03,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  62%|██████▎   | 5/8 [00:05<00:01,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  75%|███████▌  | 6/8 [00:05<00:00,  2.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:06<00:00,  3.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:06<00:00,  1.29it/s]\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=val model=\"./runs/detect/train6/weights/best.pt\" data=\"C:/Users/ganma/Downloads/dataset/data.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.215 🚀 Python-3.11.5 torch-2.1.1 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12288MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "image 1/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\755934778_232384541_1706x960.jpg: 480x800 4 License-Plates, 74.5ms\n",
      "image 2/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\Hyundai-Tucson-2021-web-1046x616.jpg: 480x800 1 License-Plate, 6.5ms\n",
      "image 3/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\IMG_3864.jpg: 800x608 1 License-Plate, 77.5ms\n",
      "image 4/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\IMG_3865.jpg: 800x608 2 License-Plates, 7.5ms\n",
      "image 5/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\IMG_3866.jpg: 800x608 1 License-Plate, 7.0ms\n",
      "image 6/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\c3.webp: 608x800 2 License-Plates, 91.0ms\n",
      "image 7/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\c4.jpg: 544x800 (no detections), 72.5ms\n",
      "image 8/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\coche1.jpg: 480x800 1 License-Plate, 6.0ms\n",
      "image 9/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\coche2.jpeg: 480x800 (no detections), 7.0ms\n",
      "image 10/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\cupra-ateca-2-1200x675.jpg: 480x800 1 License-Plate, 7.0ms\n",
      "image 11/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\mercedes-benz-eqe-suv-2023-frontal-lateral.365091.jpg: 480x800 1 License-Plate, 7.0ms\n",
      "image 12/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\renault-arkana-2020.jpg: 480x800 1 License-Plate, 7.0ms\n",
      "Speed: 2.8ms preprocess, 30.9ms inference, 6.3ms postprocess per image at shape (1, 3, 480, 800)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      "💡 Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict model=\"./runs/detect/train6/weights/best.pt\" conf=0.2 source=\"./images/\" save=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segundo modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.215 🚀 Python-3.11.5 torch-2.1.1 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12288MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "image 1/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\755934778_232384541_1706x960.jpg: 256x416 4 License_Plates, 78.0ms\n",
      "image 2/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\Hyundai-Tucson-2021-web-1046x616.jpg: 256x416 1 License_Plate, 5.5ms\n",
      "image 3/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\IMG_3864.jpg: 416x320 1 License_Plate, 92.5ms\n",
      "image 4/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\IMG_3865.jpg: 416x320 1 License_Plate, 7.0ms\n",
      "image 5/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\IMG_3866.jpg: 416x320 1 License_Plate, 6.0ms\n",
      "image 6/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\c3.webp: 320x416 1 License_Plate, 75.0ms\n",
      "image 7/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\c4.jpg: 288x416 2 License_Plates, 70.0ms\n",
      "image 8/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\coche1.jpg: 256x416 1 License_Plate, 7.0ms\n",
      "image 9/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\coche2.jpeg: 256x416 1 License_Plate, 6.5ms\n",
      "image 10/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\cupra-ateca-2-1200x675.jpg: 256x416 1 License_Plate, 6.5ms\n",
      "image 11/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\mercedes-benz-eqe-suv-2023-frontal-lateral.365091.jpg: 256x416 1 License_Plate, 6.5ms\n",
      "image 12/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\renault-arkana-2020.jpg: 256x416 1 License_Plate, 7.5ms\n",
      "Speed: 1.3ms preprocess, 30.7ms inference, 8.6ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "💡 Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict model=\"./runs/detect/train4/weights/best.pt\" conf=0.4 source=\"./images/\" save=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 4 cars, 1 truck, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 320x416 4 License_Plates, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 4 License_Plates, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 4 License_Plates, 7.5ms\n",
      "Speed: 1.5ms preprocess, 7.5ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 4 License_Plates, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 6.0ms\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 320x416 1 License_Plate, 6.0ms\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 480x640 3 cars, 1 truck, 7.5ms\n",
      "Speed: 2.0ms preprocess, 7.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 320x416 3 License_Plates, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 3 License_Plates, 5.5ms\n",
      "Speed: 1.5ms preprocess, 5.5ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 3 License_Plates, 7.5ms\n",
      "Speed: 2.0ms preprocess, 7.5ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 480x640 1 car, 6.5ms\n",
      "Speed: 2.0ms preprocess, 6.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 320x416 1 License_Plate, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 480x640 1 car, 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 320x416 1 License_Plate, 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 480x640 1 car, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 320x416 1 License_Plate, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 480x640 1 car, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 320x416 1 License_Plate, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 480x640 1 car, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 320x416 2 License_Plates, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 480x640 2 cars, 7.5ms\n",
      "Speed: 2.0ms preprocess, 7.5ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 320x416 3 License_Plates, 6.0ms\n",
      "Speed: 0.5ms preprocess, 6.0ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 2 License_Plates, 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 480x640 4 cars, 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 320x416 1 License_Plate, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 License_Plate, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 License_Plate, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 License_Plate, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 480x640 1 car, 1 truck, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 320x416 1 License_Plate, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 480x640 1 car, 1 truck, 27.5ms\n",
      "Speed: 2.5ms preprocess, 27.5ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 320x416 1 License_Plate, 6.0ms\n",
      "Speed: 0.5ms preprocess, 6.0ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 416)\n"
     ]
    }
   ],
   "source": [
    "# Carga del modelo\n",
    "model = YOLO('yolov8n.pt')\n",
    "customModel = YOLO(\"./runs/detect/train4/weights/best.pt\")\n",
    "\n",
    "# Nombre de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "folder_path = \"./images/\"\n",
    "\n",
    "image_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "reader = easyocr.Reader(['es'])\n",
    "\n",
    "def encontrar_matricula_yolo(car_img):\n",
    "    results = customModel(car_img)\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes: \n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            cv2.rectangle(car_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "for image_file in image_files:\n",
    "    # Lee la imagen desde la carpeta\n",
    "    img = cv2.imread(os.path.join(folder_path, image_file))\n",
    "    target_size = (800, 600)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    \n",
    "    # Perform inference on an image\n",
    "    results = model(img)\n",
    "\n",
    "    # Para cada detección\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Identificación de la matrícula para coches\n",
    "            if classNames[int(box.cls[0])] == \"car\":\n",
    "                # Dibuja un rectángulo negro alrededor del coche\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 0), 2)\n",
    "                # Calcular la altura de los 2/3 inferiores del recuadro\n",
    "                altura_dos_tercios = ((y2 - y1) * 2) // 3\n",
    "\n",
    "                # Recortar solo los 2/3 inferiores del recuadro\n",
    "                dos_tercios_inferiores_car_img = img[y1 + altura_dos_tercios:y2, x1:x2]\n",
    "\n",
    "                # Pasar estos 2/3 inferiores a la función encontrar_matricula\n",
    "                encontrar_matricula_yolo(dos_tercios_inferiores_car_img)\n",
    "\n",
    "                #cv2.putText(img, \"car \" + matricula_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "                \n",
    "\n",
    "        # Muestra la imagen con las detecciones\n",
    "        cv2.imshow('Image', img)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "# Cierra la ventana al finalizar\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('yolov7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54711ba1bddc392d48ca20e80feaa9b2e23d43069aa8b98ed16355091034ff6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
