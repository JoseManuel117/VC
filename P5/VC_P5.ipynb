{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import math \n",
    "import numpy as np\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde cámara, detección con yolov8 y modelo nano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 56.5ms\n",
      "Speed: 2.5ms preprocess, 56.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.3\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 46.5ms\n",
      "Speed: 2.0ms preprocess, 46.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.26\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 46.0ms\n",
      "Speed: 1.0ms preprocess, 46.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 57.0ms\n",
      "Speed: 1.5ms preprocess, 57.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.33\n",
      "Class name --> clock\n",
      "0: 480x640 1 clock, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 44.0ms\n",
      "Speed: 1.5ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.31\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 44.5ms\n",
      "Speed: 1.5ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.28\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.31\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 58.5ms\n",
      "Speed: 1.5ms preprocess, 58.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 44.0ms\n",
      "Speed: 0.5ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 43.5ms\n",
      "Speed: 0.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.3\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.26\n",
      "Class name --> clock\n",
      "0: 480x640 1 clock, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.33\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 45.0ms\n",
      "Speed: 0.5ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 47.0ms\n",
      "Speed: 0.5ms preprocess, 47.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.32\n",
      "Class name --> clock\n",
      "0: 480x640 1 clock, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 50.0ms\n",
      "Speed: 1.0ms preprocess, 50.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.26\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.31\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.28\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 46.5ms\n",
      "Speed: 0.5ms preprocess, 46.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.36\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 43.5ms\n",
      "Speed: 0.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.33\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.38\n",
      "Class name --> clock\n",
      "0: 480x640 1 clock, 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 44.0ms\n",
      "Speed: 1.5ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.29\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.3\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 0.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.4\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.36\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.5\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.55\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 person, 1 bicycle, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.51\n",
      "Class name --> person\n",
      "Confidence ---> 0.33\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 person, 1 bicycle, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.52\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> clock\n",
      "0: 480x640 1 person, 1 clock, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.6\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 2.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.53\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.5ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.65\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 person, 1 bicycle, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.64\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 49.0ms\n",
      "Speed: 1.0ms preprocess, 49.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.59\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.59\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.59\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.6\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 0.5ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.62\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.52\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.5\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.41\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.42\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.5\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.45\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.3\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.35\n",
      "Class name --> clock\n",
      "0: 480x640 1 clock, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.43\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.46\n",
      "Class name --> keyboard\n",
      "Confidence ---> 0.31\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 1 keyboard, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.3\n",
      "Class name --> bicycle\n",
      "0: 480x640 1 bicycle, 51.0ms\n",
      "Speed: 1.0ms preprocess, 51.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.54\n",
      "Class name --> clock\n",
      "0: 480x640 1 clock, 45.0ms\n",
      "Speed: 1.5ms preprocess, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.38\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.48\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.5ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.59\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> clock\n",
      "0: 480x640 1 person, 1 clock, 43.0ms\n",
      "Speed: 1.5ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.46\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.53\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.57\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 0.5ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.58\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.0ms\n",
      "Speed: 0.5ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> bicycle\n",
      "Confidence ---> 0.27\n",
      "Class name --> clock\n",
      "0: 480x640 1 person, 1 bicycle, 1 clock, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.55\n",
      "Class name --> clock\n",
      "0: 480x640 1 person, 1 clock, 44.5ms\n",
      "Speed: 1.5ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.67\n",
      "Class name --> clock\n",
      "Confidence ---> 0.65\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 1 clock, 44.5ms\n",
      "Speed: 0.5ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.68\n",
      "Class name --> person\n",
      "Confidence ---> 0.4\n",
      "Class name --> clock\n",
      "0: 480x640 1 person, 1 clock, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.75\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.75\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> clock\n",
      "Confidence ---> 0.27\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 1 clock, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> clock\n",
      "0: 480x640 1 person, 1 clock, 43.0ms\n",
      "Speed: 0.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Confidence ---> 0.42\n",
      "Class name --> bicycle\n",
      "Confidence ---> 0.34\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 1 bicycle, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 0.5ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 46.5ms\n",
      "Speed: 1.0ms preprocess, 46.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 0.5ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.0ms\n",
      "Speed: 1.5ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.67\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.5ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.61\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.8\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> clock\n",
      "0: 480x640 1 person, 1 clock, 44.0ms\n",
      "Speed: 1.5ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.8\n",
      "Class name --> person\n",
      "Confidence ---> 0.75\n",
      "Class name --> clock\n",
      "0: 480x640 1 person, 1 clock, 44.0ms\n",
      "Speed: 0.5ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.8\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> clock\n",
      "0: 480x640 1 person, 1 clock, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> clock\n",
      "0: 480x640 1 person, 1 clock, 43.5ms\n",
      "Speed: 0.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> clock\n",
      "0: 480x640 1 person, 1 clock, 44.0ms\n",
      "Speed: 0.5ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.64\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> clock\n",
      "0: 480x640 1 person, 1 clock, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.34\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.63\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 0.5ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> chair\n",
      "0: 480x640 1 person, 1 chair, 44.0ms\n",
      "Speed: 0.5ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.5ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 0.5ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.5ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.5ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 46.5ms\n",
      "Speed: 1.0ms preprocess, 46.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> chair\n",
      "0: 480x640 1 person, 1 chair, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 46.5ms\n",
      "Speed: 0.5ms preprocess, 46.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> chair\n",
      "0: 480x640 1 person, 1 chair, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.96\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.96\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 47.5ms\n",
      "Speed: 1.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 0.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> chair\n",
      "0: 480x640 2 persons, 1 chair, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 0.5ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 0.5ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.44\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.0ms\n",
      "Speed: 1.5ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 0.5ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 48.5ms\n",
      "Speed: 1.0ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 46.0ms\n",
      "Speed: 1.0ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 52.0ms\n",
      "Speed: 1.0ms preprocess, 52.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 46.0ms\n",
      "Speed: 1.0ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 0.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 0.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 0.5ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 49.0ms\n",
      "Speed: 2.5ms preprocess, 49.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 48.5ms\n",
      "Speed: 1.0ms preprocess, 48.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.49\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.29\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.44\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.3\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 44.0ms\n",
      "Speed: 1.5ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.4\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.28\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 44.0ms\n",
      "Speed: 0.5ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.44\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.28\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.33\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.35\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.26\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.3\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.28\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.45\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 47.0ms\n",
      "Speed: 2.0ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.33\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.29\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.67\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.42\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.38\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 41.5ms\n",
      "Speed: 1.5ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.3\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.45\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.49\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.42\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 52.0ms\n",
      "Speed: 1.0ms preprocess, 52.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.4\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 43.0ms\n",
      "Speed: 0.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.26\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.5ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.35\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.65\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.36\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.27\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 3 cell phones, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.26\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 43.5ms\n",
      "Speed: 1.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.46\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.31\n",
      "Class name --> remote\n",
      "0: 480x640 1 person, 1 remote, 1 cell phone, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 51.0ms\n",
      "Speed: 1.0ms preprocess, 51.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.33\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 0.5ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.58\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.5ms\n",
      "Speed: 1.5ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.0ms\n",
      "Speed: 0.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.0ms\n",
      "Speed: 0.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.69\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.64\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.67\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.5ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 0.5ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.68\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.68\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 46.0ms\n",
      "Speed: 1.0ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.69\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.69\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.0ms\n",
      "Speed: 1.5ms preprocess, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.78\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 61.0ms\n",
      "Speed: 0.5ms preprocess, 61.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 0.5ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.5ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 0.5ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 48.5ms\n",
      "Speed: 1.0ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 55.0ms\n",
      "Speed: 1.0ms preprocess, 55.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.0ms\n",
      "Speed: 0.5ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 0.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.5ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.4\n",
      "Class name --> cup\n",
      "Confidence ---> 0.28\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 46.0ms\n",
      "Speed: 1.5ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.5ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 0.5ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 0.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 0.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 47.5ms\n",
      "Speed: 1.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 0.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 61.5ms\n",
      "Speed: 1.0ms preprocess, 61.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 46.5ms\n",
      "Speed: 0.5ms preprocess, 46.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.0ms\n",
      "Speed: 1.5ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.8\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 48.5ms\n",
      "Speed: 1.5ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 0.5ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.8\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 46.0ms\n",
      "Speed: 1.0ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 0.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.8\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.78\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "Confidence ---> 0.52\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.78\n",
      "Class name --> person\n",
      "Confidence ---> 0.77\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.57\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.0ms\n",
      "Speed: 0.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 41.5ms\n",
      "Speed: 1.5ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.5ms\n",
      "Speed: 0.5ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 2.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 49.5ms\n",
      "Speed: 1.5ms preprocess, 49.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 46.0ms\n",
      "Speed: 1.0ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.27\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.46\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 48.5ms\n",
      "Speed: 1.0ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Speed: 0.5ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.46\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.6\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 42.0ms\n",
      "Speed: 1.5ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.53\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 47.0ms\n",
      "Speed: 1.0ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.53\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.45\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 46.0ms\n",
      "Speed: 1.0ms preprocess, 46.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 44.5ms\n",
      "Speed: 0.5ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> cup\n",
      "Confidence ---> 0.35\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 49.5ms\n",
      "Speed: 1.0ms preprocess, 49.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.6\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 47.5ms\n",
      "Speed: 1.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.33\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.52\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.35\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.61\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.35\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.62\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.41\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.64\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.38\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.33\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.4\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.4\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.27\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 43.0ms\n",
      "Speed: 1.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.33\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.29\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 46.5ms\n",
      "Speed: 1.0ms preprocess, 46.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 60.5ms\n",
      "Speed: 1.0ms preprocess, 60.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.28\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.49\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.52\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.54\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.71\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 1 cell phone, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.6\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.7\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.59\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.79\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.61\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.85\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.81\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 46.5ms\n",
      "Speed: 0.5ms preprocess, 46.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "Confidence ---> 0.78\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 46.0ms\n",
      "Speed: 1.0ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.8\n",
      "Class name --> person\n",
      "Confidence ---> 0.6\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.26\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 44.0ms\n",
      "Speed: 0.5ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "Confidence ---> 0.58\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.31\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.27\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 3 cell phones, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Confidence ---> 0.46\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.71\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.69\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.75\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.7\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 51.0ms\n",
      "Speed: 1.0ms preprocess, 51.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.68\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.51\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.6\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 44.0ms\n",
      "Speed: 0.5ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.54\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.6\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.58\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.57\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.59\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.74\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.67\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 44.0ms\n",
      "Speed: 1.5ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.77\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.77\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 49.5ms\n",
      "Speed: 1.0ms preprocess, 49.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 0.5ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "Confidence ---> 0.44\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 41.0ms\n",
      "Speed: 1.5ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.42\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 0.5ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.53\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.64\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.4\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 0.5ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.53\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.7\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.58\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 47.0ms\n",
      "Speed: 3.0ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.42\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.29\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.46\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.26\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.3\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 41.0ms\n",
      "Speed: 0.5ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.4\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.45\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.45\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.28\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.48\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.29\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 42.0ms\n",
      "Speed: 0.5ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.45\n",
      "Class name --> cup\n",
      "Confidence ---> 0.31\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.39\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.55\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.36\n",
      "Class name --> cup\n",
      "Confidence ---> 0.27\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cup, 2 cell phones, 48.5ms\n",
      "Speed: 1.5ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.33\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.31\n",
      "Class name --> cup\n",
      "Confidence ---> 0.29\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cup, 2 cell phones, 43.0ms\n",
      "Speed: 0.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.3\n",
      "Class name --> cup\n",
      "Confidence ---> 0.26\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cup, 2 cell phones, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.48\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.4\n",
      "Class name --> cup\n",
      "Confidence ---> 0.37\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cup, 2 cell phones, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.45\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.35\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 2 cell phones, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.37\n",
      "Class name --> cup\n",
      "Confidence ---> 0.26\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.26\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cup, 3 cell phones, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> cell phone\n",
      "Confidence ---> 0.29\n",
      "Class name --> cup\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> cell phone\n",
      "0: 480x640 1 person, 1 cell phone, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 46.5ms\n",
      "Speed: 2.0ms preprocess, 46.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 57.5ms\n",
      "Speed: 1.0ms preprocess, 57.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 46.5ms\n",
      "Speed: 1.0ms preprocess, 46.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.5ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.33\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.42\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 60.0ms\n",
      "Speed: 1.0ms preprocess, 60.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 48.5ms\n",
      "Speed: 1.0ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 0.5ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.29\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 60.0ms\n",
      "Speed: 1.0ms preprocess, 60.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 57.5ms\n",
      "Speed: 1.0ms preprocess, 57.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Speed: 0.5ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.29\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 52.0ms\n",
      "Speed: 1.0ms preprocess, 52.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.4\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 45.0ms\n",
      "Speed: 0.5ms preprocess, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# Carga del modelo\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Nombre de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "\n",
    "# Captura desde lawebcam\n",
    "vid = cv2.VideoCapture(0)\n",
    "  \n",
    "while(True):      \n",
    "    # fotograma a fotograma\n",
    "    ret, img = vid.read()\n",
    "  \n",
    "    # si hay imagen válida\n",
    "    if ret:  \n",
    "        # Perform inference on an image\n",
    "        results = model(img, stream=True)\n",
    "        \n",
    "        # Para cada detección\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                # Contenedor\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "                \n",
    "                # Confianza\n",
    "                confidence = math.ceil((box.conf[0]*100))/100\n",
    "                print(\"Confidence --->\",confidence)\n",
    "\n",
    "                # Clase\n",
    "                cls = int(box.cls[0])\n",
    "                print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "                # Convierte identificador numérico de clase a un color RGB\n",
    "                escala = int((cls / len(classNames)) * 255 * 3)\n",
    "                if escala >= 255*2:\n",
    "                    R = 255\n",
    "                    G = 255\n",
    "                    B = escala - 255*2\n",
    "                else:\n",
    "                    if escala >= 255:\n",
    "                        R = 255\n",
    "                        G = escala - 255\n",
    "                        B = 0\n",
    "                    else:\n",
    "                        R = escala\n",
    "                        G = 0\n",
    "                        B = 0\n",
    "\n",
    "                # Dibuja el contenedor y clase\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "                cv2.putText(img, classNames[cls] , [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "        # Muestra fotograma\n",
    "        cv2.imshow('Vid', img)\n",
    "    \n",
    "    # Detenemos pulsado ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "  \n",
    "# Libera el objeto de captura\n",
    "vid.release()\n",
    "# Destruye ventanas\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconocimiento de caracteres tras instalar pytesseract y tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 4 cars, 1 truck, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ganma\\AppData\\Local\\Temp\\ipykernel_22312\\1027782351.py:33: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box = np.int0(box)  # Redondea los valores a enteros\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 1 car, 8.5ms\n",
      "Speed: 1.5ms preprocess, 8.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 1 truck, 7.5ms\n",
      "Speed: 1.5ms preprocess, 7.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 6.0ms\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 6.0ms\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 1 truck, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 1 truck, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Para cada detección\\nfor r in results:\\n    boxes = r.boxes\\n\\n    for box in boxes:\\n        x1, y1, x2, y2 = box.xyxy[0]\\n        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\\n        \\n        # [ ... Tu código para dibujar el contenedor y clase ... ]\\n\\n        # Identificación de la matrícula para coches\\n        if classNames[int(box.cls[0])] == \"car\":\\n            # Seleccionar la parte inferior del coche para buscar la matrícula\\n            car_img = img[y1:y2, x1:x2]\\n\\n            # Aplica la función encontrar_matricula a la imagen del coche\\n            encontrar_matricula(car_img)\\n\\n            # Dibujar el resultado de vuelta en la imagen original\\n            img[y1:y2, x1:x2] = car_img\\n\\n# Muestra la imagen\\ncv2.imshow(\\'Imagen Detectada\\', img)\\ncv2.waitKey(0)\\ncv2.destroyAllWindows()\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga del modelo\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Nombre de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "folder_path = \"./images/\"\n",
    "\n",
    "image_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "reader = easyocr.Reader(['es'])\n",
    "\n",
    "def encontrar_matricula(car_img):\n",
    "    gray = cv2.cvtColor(car_img, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edged = cv2.Canny(blur, 30, 150)\n",
    "\n",
    "    contours, _ = cv2.findContours(edged, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for cnt in contours:\n",
    "        rect = cv2.minAreaRect(cnt)  # Obtiene el rectángulo rotado más pequeño\n",
    "        box = cv2.boxPoints(rect)  # Obtiene los cuatro puntos del rectángulo\n",
    "        box = np.int0(box)  # Redondea los valores a enteros\n",
    "\n",
    "        # Calcular el área del rectángulo para filtrar contornos pequeños\n",
    "        area = cv2.contourArea(box)\n",
    "        if 800 < area < 5000:\n",
    "            # Extraer la porción de la imagen dentro del rectángulo\n",
    "            mask = np.zeros_like(gray)\n",
    "            cv2.drawContours(mask, [box], 0, 255, -1)\n",
    "            masked = cv2.bitwise_and(car_img, car_img, mask=mask)\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            crop = masked[y:y+h, x:x+w]\n",
    "\n",
    "            # Convertir recorte a formato RGB para EasyOCR\n",
    "            crop_rgb = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Aplicar OCR usando EasyOCR\n",
    "            results = reader.readtext(crop_rgb)\n",
    "\n",
    "            # Si se detecta texto, dibujar el rectángulo y agregar texto en la esquina inferior izquierda del rectángulo\n",
    "            if results:\n",
    "                # Agregar texto de matrícula en la esquina inferior izquierda del rectángulo\n",
    "                matricula_text = results[0][-2]\n",
    "                if len(matricula_text) >= 2:\n",
    "                    cv2.drawContours(car_img, [box], 0, (0, 255, 0), 3)\n",
    "                    return matricula_text\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "\"\"\"\n",
    "def encontrar_matricula(car_img):\n",
    "    # Convertir a escala de grises\n",
    "    gray = cv2.cvtColor(car_img, cv2.COLOR_BGR2GRAY)\n",
    "    # Aplicar desenfoque para reducir el ruido\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    # Detector de bordes\n",
    "    edged = cv2.Canny(blur, 30, 150)\n",
    "\n",
    "    # Buscar contornos\n",
    "    contours, _ = cv2.findContours(edged, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    rectangulos = []\n",
    "\n",
    "    for cnt in contours:\n",
    "        # Aproximar el contorno a un polígono\n",
    "        epsilon = 0.05 * cv2.arcLength(cnt, True)  # Aumenta el valor de epsilon para una forma más general\n",
    "        approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "        \n",
    "        # Considerar contornos con un número de vértices cercano a 4 (por ejemplo, de 4 a 10)\n",
    "        if 4 <= len(approx) <= 10:  \n",
    "            area = cv2.contourArea(cnt)\n",
    "            # Ajustar los umbrales de área para incluir un rango más amplio\n",
    "            if 50 < area < 20000:  # Los umbrales dependen del tamaño esperado de los rectángulos\n",
    "                x, y, w, h = cv2.boundingRect(approx)\n",
    "                aspect_ratio = w / float(h)\n",
    "\n",
    "                # Considerar un rango más amplio de proporciones de aspecto\n",
    "                if 0.2 < aspect_ratio < 5:\n",
    "                    rectangulos.append(cnt)\n",
    "                    # Dibujar el contorno en la imagen recortada, no en la original\n",
    "                    cv2.drawContours(car_img, [cnt], 0, (0, 255, 0), 3)\n",
    "\"\"\"\n",
    "\n",
    "for image_file in image_files:\n",
    "    # Lee la imagen desde la carpeta\n",
    "    img = cv2.imread(os.path.join(folder_path, image_file))\n",
    "    target_size = (800, 600)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    \n",
    "    # Perform inference on an image\n",
    "    results = model(img)\n",
    "\n",
    "    # Para cada detección\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Identificación de la matrícula para coches\n",
    "            if classNames[int(box.cls[0])] == \"car\":\n",
    "                # Dibuja un rectángulo negro alrededor del coche\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 0), 2)\n",
    "                # Calcular la mitad de la altura del recuadro\n",
    "                mitad_altura = (y2 - y1) // 2\n",
    "\n",
    "                # Recortar solo la mitad inferior del recuadro\n",
    "                mitad_inferior_car_img = img[y1 + mitad_altura:y2, x1:x2]\n",
    "\n",
    "                # Pasar esta mitad inferior a la función encontrar_matricula\n",
    "                matricula_text= encontrar_matricula(mitad_inferior_car_img)\n",
    "\n",
    "                cv2.putText(img, \"car \" + matricula_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "                \n",
    "\n",
    "        # Muestra la imagen con las detecciones\n",
    "        cv2.imshow('Image', img)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "# Cierra la ventana al finalizar\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\"\"\"\n",
    "# Para cada detección\n",
    "for r in results:\n",
    "    boxes = r.boxes\n",
    "\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0]\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "        \n",
    "        # [ ... Tu código para dibujar el contenedor y clase ... ]\n",
    "\n",
    "        # Identificación de la matrícula para coches\n",
    "        if classNames[int(box.cls[0])] == \"car\":\n",
    "            # Seleccionar la parte inferior del coche para buscar la matrícula\n",
    "            car_img = img[y1:y2, x1:x2]\n",
    "\n",
    "            # Aplica la función encontrar_matricula a la imagen del coche\n",
    "            encontrar_matricula(car_img)\n",
    "\n",
    "            # Dibujar el resultado de vuelta en la imagen original\n",
    "            img[y1:y2, x1:x2] = car_img\n",
    "\n",
    "# Muestra la imagen\n",
    "cv2.imshow('Imagen Detectada', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eng', 'osd']\n",
      "Hasta el infinito y mas alla\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tesseract\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# Previamente debes descargar los ejecutables\n",
    "# Si la ruta de Tesseract no está en el PATH, ruta al ejecutable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract'\n",
    "\n",
    "# Lenguajes disponibles\n",
    "print(pytesseract.get_languages(config=''))\n",
    "\n",
    "#Cargo imagen y ocnvierto a RGB\n",
    "img = cv2.imread('toy.tif') \n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#Aplica reconocedor a imagen cargada\n",
    "print(pytesseract.image_to_string(img_rgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconocimiento decaracteres tras instalar easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([[49, 85], [617, 85], [617, 147], [49, 147]], 'Hasta el infinito y más allá', 0.6744627670805162)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Carga del modelo de lengua\n",
    "reader = easyocr.Reader(['es']) \n",
    "\n",
    "#Reconocimiento de una imagen\n",
    "result = reader.readtext('toy.tif')\n",
    "print(result)\n",
    "\n",
    "#Con restricción de caracteres reconocibles\n",
    "#result = reader.readtext('toy.tif', allowlist ='0123456789')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Ultralytics YOLOv8.0.215 🚀 Python-3.11.5 torch-2.1.1 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12288MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=C:/Users/ganma/Downloads/dataset/data.yaml, epochs=100, patience=50, batch=16, imgsz=800, save=True, save_period=-1, cache=False, device=None, workers=0, project=None, name=train6, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train6\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLOv8n summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\ganma\\Downloads\\train\\labels.cache... 1156 images, 64 backgrounds, 0 corrupt: 100%|██████████| 1156/1156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 82, len(boxes) = 1772. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\ganma\\Downloads\\valid\\labels.cache... 118 images, 0 backgrounds, 0 corrupt: 100%|██████████| 118/118 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 11, len(boxes) = 204. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train6\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 800 train, 800 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train6\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      3.25G      3.574      5.764      4.164         12        800: 100%|██████████| 73/73 [00:30<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204   0.000621      0.108   0.000398   0.000149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      3.23G       3.19      4.921      3.618          6        800: 100%|██████████| 73/73 [00:28<00:00,  2.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204   0.000763      0.132   0.000734   0.000245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      3.26G      2.925      4.411      3.188          5        800: 100%|██████████| 73/73 [00:27<00:00,  2.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204    0.00147      0.255    0.00112   0.000401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      3.26G      2.789      3.933      2.981         10        800: 100%|██████████| 73/73 [00:27<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204     0.0294     0.0294    0.00828    0.00289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      3.13G      2.594      3.506      2.824          7        800: 100%|██████████| 73/73 [00:27<00:00,  2.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.288      0.167      0.112     0.0318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      3.25G      2.511      3.161      2.725         23        800: 100%|██████████| 73/73 [00:28<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.278      0.191       0.14     0.0404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      3.23G      2.385      2.943      2.609         14        800: 100%|██████████| 73/73 [00:28<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.318      0.225        0.2     0.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      3.26G      2.313      2.847       2.48          8        800: 100%|██████████| 73/73 [00:28<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.396      0.325       0.24      0.094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      3.23G      2.344      2.716       2.47         10        800: 100%|██████████| 73/73 [00:28<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.496      0.279      0.284      0.117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      3.25G      2.192      2.557       2.33         15        800: 100%|██████████| 73/73 [00:28<00:00,  2.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.416      0.289      0.277      0.102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      3.23G      2.138      2.498       2.28          5        800: 100%|██████████| 73/73 [00:28<00:00,  2.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204       0.47      0.404       0.38      0.153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100      3.23G       2.06      2.391      2.225          9        800: 100%|██████████| 73/73 [00:27<00:00,  2.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.556      0.377      0.379      0.155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100      3.23G        2.1      2.365      2.239         12        800: 100%|██████████| 73/73 [00:27<00:00,  2.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.471      0.288      0.306       0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100      3.23G      2.021      2.258      2.197          8        800: 100%|██████████| 73/73 [00:27<00:00,  2.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.557      0.368      0.373      0.144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100      3.29G       2.06      2.289      2.178         10        800: 100%|██████████| 73/73 [00:27<00:00,  2.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.589      0.328       0.37      0.156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      3.24G      1.961      2.172      2.105          6        800: 100%|██████████| 73/73 [00:27<00:00,  2.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.676      0.431      0.462      0.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100      3.23G       1.95      2.128      2.091         11        800: 100%|██████████| 73/73 [00:27<00:00,  2.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.658      0.431      0.436      0.198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100      3.25G      1.922      2.107      2.044          6        800: 100%|██████████| 73/73 [00:27<00:00,  2.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.563      0.424      0.453      0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      3.23G      1.905      2.025      2.051          5        800: 100%|██████████| 73/73 [00:27<00:00,  2.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.721      0.441      0.492      0.236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      3.13G      1.888      1.976      1.991          9        800: 100%|██████████| 73/73 [00:27<00:00,  2.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.549      0.485      0.479      0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      3.23G      1.904      2.038      2.026         11        800: 100%|██████████| 73/73 [00:27<00:00,  2.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.592       0.51      0.532      0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      3.12G      1.855      1.936      1.979          9        800: 100%|██████████| 73/73 [00:27<00:00,  2.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.723      0.422        0.5      0.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      3.24G      1.812      1.876      1.925         10        800: 100%|██████████| 73/73 [00:27<00:00,  2.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.647      0.441      0.478      0.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      3.23G      1.802      1.871      1.933         14        800: 100%|██████████| 73/73 [00:27<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.842      0.446      0.567      0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100      3.23G      1.806      1.877      1.933         11        800: 100%|██████████| 73/73 [00:27<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.655      0.484      0.543      0.274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100      3.23G      1.799        1.8      1.901         13        800: 100%|██████████| 73/73 [00:27<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.745      0.459      0.502      0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100      3.23G      1.761      1.843      1.956          4        800: 100%|██████████| 73/73 [00:27<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.751      0.531      0.574      0.265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      3.23G      1.785      1.788      1.922         10        800: 100%|██████████| 73/73 [00:27<00:00,  2.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.812      0.466      0.568      0.273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      3.23G      1.716      1.696      1.875         10        800: 100%|██████████| 73/73 [00:27<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.781      0.559      0.611      0.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100      3.23G      1.738      1.728      1.908          7        800: 100%|██████████| 73/73 [00:27<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.769      0.523      0.588      0.275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100      3.24G      1.737      1.733      1.891          9        800: 100%|██████████| 73/73 [00:27<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.813      0.489       0.55      0.263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100      3.23G       1.71      1.726       1.87          5        800: 100%|██████████| 73/73 [00:27<00:00,  2.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.715      0.529      0.585      0.272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100      3.12G      1.695      1.642       1.83         13        800: 100%|██████████| 73/73 [00:27<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.777      0.478       0.55      0.276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100      3.23G      1.682      1.641      1.837         10        800: 100%|██████████| 73/73 [00:27<00:00,  2.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204        0.8       0.49      0.556      0.235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100      3.26G      1.693      1.666      1.846          5        800: 100%|██████████| 73/73 [00:27<00:00,  2.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.733       0.51      0.574      0.264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100      3.18G      1.668      1.588      1.829         11        800: 100%|██████████| 73/73 [00:27<00:00,  2.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204       0.74      0.539      0.612      0.295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100      3.26G      1.695      1.567      1.823          4        800: 100%|██████████| 73/73 [00:27<00:00,  2.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.815      0.538       0.63      0.292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100      3.22G      1.634      1.526      1.787          3        800: 100%|██████████| 73/73 [00:27<00:00,  2.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.867      0.512      0.619      0.294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100      3.24G      1.633      1.554      1.804          8        800: 100%|██████████| 73/73 [00:27<00:00,  2.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.884      0.521      0.615      0.307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100      3.23G      1.639      1.543      1.793          3        800: 100%|██████████| 73/73 [00:28<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.774      0.583      0.643      0.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100      3.23G      1.602      1.502      1.791          2        800: 100%|██████████| 73/73 [00:27<00:00,  2.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.823      0.554      0.651       0.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100      3.22G      1.605      1.487      1.789          6        800: 100%|██████████| 73/73 [00:27<00:00,  2.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.847      0.569      0.631      0.283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100      3.23G      1.626      1.458      1.768          5        800: 100%|██████████| 73/73 [00:28<00:00,  2.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204       0.92      0.569      0.663      0.279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100      3.24G      1.616      1.491      1.772         10        800: 100%|██████████| 73/73 [00:27<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.798      0.578      0.669      0.328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100      3.12G      1.555      1.409      1.723          9        800: 100%|██████████| 73/73 [00:27<00:00,  2.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.799      0.559       0.64      0.318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100      3.25G      1.575      1.437      1.733         12        800: 100%|██████████| 73/73 [00:28<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204       0.85      0.598       0.68      0.358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100      3.26G      1.536      1.378      1.709          6        800: 100%|██████████| 73/73 [00:27<00:00,  2.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.862      0.564      0.668      0.316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100      3.23G      1.508      1.359      1.693          6        800: 100%|██████████| 73/73 [00:28<00:00,  2.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.904      0.597      0.701      0.327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100      3.26G      1.563      1.366      1.727         15        800: 100%|██████████| 73/73 [00:28<00:00,  2.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.814      0.558      0.646      0.336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100      3.22G      1.524      1.337      1.704         10        800: 100%|██████████| 73/73 [00:29<00:00,  2.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.907      0.529      0.661      0.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100      3.23G      1.521      1.318      1.711          5        800: 100%|██████████| 73/73 [00:28<00:00,  2.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.853      0.628      0.711       0.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100      3.23G      1.538      1.324      1.724         12        800: 100%|██████████| 73/73 [00:28<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.862      0.615       0.71      0.311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100      3.13G      1.501      1.294      1.677         12        800: 100%|██████████| 73/73 [00:30<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.793      0.608       0.65      0.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100      3.22G      1.489      1.287      1.666          4        800: 100%|██████████| 73/73 [00:29<00:00,  2.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.849      0.613       0.69      0.316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100      3.26G      1.524      1.303      1.697         16        800: 100%|██████████| 73/73 [00:29<00:00,  2.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.842      0.618      0.704      0.346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100      3.23G      1.502      1.279      1.694          9        800: 100%|██████████| 73/73 [00:28<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.865      0.642      0.712      0.346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100      3.24G      1.504      1.264      1.671         14        800: 100%|██████████| 73/73 [00:28<00:00,  2.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.893      0.653      0.738      0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100      3.22G      1.471      1.203      1.646          8        800: 100%|██████████| 73/73 [00:28<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.863      0.618      0.706      0.362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100      3.23G       1.49      1.207       1.64         11        800: 100%|██████████| 73/73 [00:28<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.823      0.657      0.721      0.378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100      3.26G      1.465      1.241      1.653         10        800: 100%|██████████| 73/73 [00:28<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.848      0.627        0.7      0.332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100      3.24G      1.441      1.172      1.638         14        800: 100%|██████████| 73/73 [00:29<00:00,  2.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.875      0.653      0.741      0.363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100      3.22G      1.447        1.2       1.64          6        800: 100%|██████████| 73/73 [00:28<00:00,  2.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.916      0.652       0.74       0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100      3.23G      1.447      1.163      1.624          9        800: 100%|██████████| 73/73 [00:28<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.872      0.634      0.731      0.383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100      3.23G      1.456      1.184      1.635          7        800: 100%|██████████| 73/73 [00:28<00:00,  2.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.914      0.622      0.725      0.355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100      3.23G      1.456      1.154      1.641          9        800: 100%|██████████| 73/73 [00:28<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.873      0.642      0.747      0.377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100      3.22G       1.39      1.117      1.591         10        800: 100%|██████████| 73/73 [00:28<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.892      0.647      0.737       0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100      3.23G      1.398      1.105      1.642          3        800: 100%|██████████| 73/73 [00:28<00:00,  2.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.924      0.599      0.738      0.373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100      3.23G      1.439      1.134       1.64          3        800: 100%|██████████| 73/73 [00:28<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.828      0.696      0.749      0.357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100      3.26G      1.413      1.102      1.581         10        800: 100%|██████████| 73/73 [00:28<00:00,  2.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.851      0.676      0.739      0.363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100      3.12G      1.383      1.104      1.591          6        800: 100%|██████████| 73/73 [00:28<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.838      0.683      0.752      0.393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100      3.29G      1.383      1.086      1.577         10        800: 100%|██████████| 73/73 [00:28<00:00,  2.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.866      0.672       0.76      0.372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100      3.12G      1.389      1.042      1.581          6        800: 100%|██████████| 73/73 [00:28<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.874      0.696      0.774      0.413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100      3.23G      1.377      1.052      1.547          9        800: 100%|██████████| 73/73 [00:28<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.847      0.701       0.75       0.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100      3.22G      1.373      1.068      1.573          6        800: 100%|██████████| 73/73 [00:28<00:00,  2.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.854      0.662      0.753      0.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100      3.23G      1.386       1.07       1.58          5        800: 100%|██████████| 73/73 [00:28<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.944      0.618       0.74      0.365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100      3.23G      1.381      1.044      1.578         10        800: 100%|██████████| 73/73 [00:28<00:00,  2.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.942      0.637      0.779      0.372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100      3.23G      1.371      1.038      1.553         11        800: 100%|██████████| 73/73 [00:28<00:00,  2.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.824      0.687      0.757       0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100      3.22G      1.354      1.028      1.594         10        800: 100%|██████████| 73/73 [00:28<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.904      0.667      0.765      0.387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100      3.23G      1.368      1.053      1.567         13        800: 100%|██████████| 73/73 [00:28<00:00,  2.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.891      0.683      0.768      0.387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100      3.16G      1.345     0.9923      1.541          8        800: 100%|██████████| 73/73 [00:29<00:00,  2.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.867      0.691       0.76      0.378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100      3.24G      1.336      1.001      1.543         12        800: 100%|██████████| 73/73 [00:28<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.819      0.712      0.773      0.401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100      3.22G       1.32     0.9889      1.544          7        800: 100%|██████████| 73/73 [00:29<00:00,  2.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.898      0.701      0.789      0.406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100      3.23G      1.312     0.9827      1.544          4        800: 100%|██████████| 73/73 [00:28<00:00,  2.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.892      0.725        0.8      0.415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100      3.24G      1.304     0.9786      1.532         10        800: 100%|██████████| 73/73 [00:28<00:00,  2.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204       0.88      0.725      0.807      0.403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100      3.24G      1.308     0.9594      1.506          8        800: 100%|██████████| 73/73 [00:28<00:00,  2.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.876      0.676       0.77      0.387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100      3.22G       1.28     0.9577      1.494          9        800: 100%|██████████| 73/73 [00:29<00:00,  2.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.882      0.695      0.777      0.399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100      3.24G       1.29     0.9452      1.538          6        800: 100%|██████████| 73/73 [00:28<00:00,  2.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.887      0.686      0.769      0.404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100      3.13G      1.281     0.9536      1.497         14        800: 100%|██████████| 73/73 [00:29<00:00,  2.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.879      0.674      0.777      0.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100      3.26G      1.282     0.9706      1.514         10        800: 100%|██████████| 73/73 [00:30<00:00,  2.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.879      0.701       0.78      0.398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/100      3.12G      1.271      0.922      1.497          8        800: 100%|██████████| 73/73 [00:29<00:00,  2.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.872      0.703       0.79      0.395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/100      3.24G      1.224     0.8191      1.486          7        800: 100%|██████████| 73/73 [00:26<00:00,  2.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.914      0.733      0.803        0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/100      3.23G       1.18     0.7741      1.453          8        800: 100%|██████████| 73/73 [00:26<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.892      0.711      0.797      0.422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/100      3.23G      1.165     0.7805      1.443          9        800: 100%|██████████| 73/73 [00:27<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.828      0.734      0.778       0.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/100      3.22G      1.187     0.7904      1.461          4        800: 100%|██████████| 73/73 [00:26<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204        0.9      0.706      0.796      0.421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/100      3.24G      1.151     0.7599      1.427          7        800: 100%|██████████| 73/73 [00:26<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.859      0.711      0.787      0.416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/100      3.23G      1.149     0.7436      1.439          4        800: 100%|██████████| 73/73 [00:26<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.879      0.716      0.781       0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/100      3.23G      1.145     0.7585      1.423          4        800: 100%|██████████| 73/73 [00:26<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.885      0.721      0.801      0.414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/100      3.22G      1.117     0.7272      1.417          5        800: 100%|██████████| 73/73 [00:26<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.864      0.721      0.789      0.412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/100      3.26G      1.126     0.7366      1.415          9        800: 100%|██████████| 73/73 [00:27<00:00,  2.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.877      0.734      0.801      0.409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/100      3.23G      1.131     0.7439      1.407          6        800: 100%|██████████| 73/73 [00:26<00:00,  2.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204       0.89       0.73      0.795      0.414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100 epochs completed in 0.832 hours.\n",
      "Optimizer stripped from runs\\detect\\train6\\weights\\last.pt, 6.3MB\n",
      "Optimizer stripped from runs\\detect\\train6\\weights\\best.pt, 6.3MB\n",
      "\n",
      "Validating runs\\detect\\train6\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.215 🚀 Python-3.11.5 torch-2.1.1 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12288MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118        204      0.885      0.716      0.797      0.422\n",
      "Speed: 0.2ms preprocess, 2.0ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    # Initialize the model\n",
    "    model = YOLO(\"yolov8n.yaml\")\n",
    "\n",
    "    # Train the model with adjusted settings\n",
    "    results = model.train(data='C:/Users/ganma/Downloads/dataset/data.yaml', \n",
    "                          epochs=100, \n",
    "                          imgsz=800, \n",
    "                          plots=True, \n",
    "                          workers=0)  # Set workers to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.215 🚀 Python-3.11.5 torch-2.1.1 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12288MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 11, len(boxes) = 204. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "                   all        118        204      0.898      0.721      0.802      0.426\n",
      "Speed: 1.9ms preprocess, 4.6ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val\u001b[0m\n",
      "💡 Learn more at https://docs.ultralytics.com/modes/val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\ganma\\Downloads\\valid\\labels.cache... 118 images, 0 backgrounds, 0 corrupt: 100%|██████████| 118/118 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\ganma\\Downloads\\valid\\labels.cache... 118 images, 0 backgrounds, 0 corrupt: 100%|██████████| 118/118 [00:00<?, ?it/s]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/8 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  12%|█▎        | 1/8 [00:04<00:33,  4.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  25%|██▌       | 2/8 [00:05<00:13,  2.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  38%|███▊      | 3/8 [00:05<00:06,  1.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|█████     | 4/8 [00:05<00:03,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  62%|██████▎   | 5/8 [00:05<00:01,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  75%|███████▌  | 6/8 [00:05<00:00,  2.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:06<00:00,  3.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:06<00:00,  1.29it/s]\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=val model=\"./runs/detect/train6/weights/best.pt\" data=\"C:/Users/ganma/Downloads/dataset/data.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.215 🚀 Python-3.11.5 torch-2.1.1 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12288MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "image 1/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\755934778_232384541_1706x960.jpg: 480x800 4 License-Plates, 74.5ms\n",
      "image 2/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\Hyundai-Tucson-2021-web-1046x616.jpg: 480x800 1 License-Plate, 6.5ms\n",
      "image 3/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\IMG_3864.jpg: 800x608 1 License-Plate, 77.5ms\n",
      "image 4/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\IMG_3865.jpg: 800x608 2 License-Plates, 7.5ms\n",
      "image 5/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\IMG_3866.jpg: 800x608 1 License-Plate, 7.0ms\n",
      "image 6/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\c3.webp: 608x800 2 License-Plates, 91.0ms\n",
      "image 7/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\c4.jpg: 544x800 (no detections), 72.5ms\n",
      "image 8/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\coche1.jpg: 480x800 1 License-Plate, 6.0ms\n",
      "image 9/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\coche2.jpeg: 480x800 (no detections), 7.0ms\n",
      "image 10/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\cupra-ateca-2-1200x675.jpg: 480x800 1 License-Plate, 7.0ms\n",
      "image 11/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\mercedes-benz-eqe-suv-2023-frontal-lateral.365091.jpg: 480x800 1 License-Plate, 7.0ms\n",
      "image 12/12 c:\\Users\\ganma\\Documents\\VC\\VC\\VC\\P5\\images\\renault-arkana-2020.jpg: 480x800 1 License-Plate, 7.0ms\n",
      "Speed: 2.8ms preprocess, 30.9ms inference, 6.3ms postprocess per image at shape (1, 3, 480, 800)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      "💡 Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict model=\"./runs/detect/train6/weights/best.pt\" conf=0.2 source=\"./images/\" save=True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('yolov7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54711ba1bddc392d48ca20e80feaa9b2e23d43069aa8b98ed16355091034ff6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
