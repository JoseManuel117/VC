{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4442edb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ganma\\anaconda3\\envs\\deepface_P6\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from deepface import DeepFace\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fd4a50",
   "metadata": {},
   "source": [
    "# Process image folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './faces'\n",
    "\n",
    "print(folder)\n",
    "\n",
    "for file_name in os.listdir(folder):\n",
    "    # Asume imágenes en formato png o jpg\n",
    "    if file_name.endswith('.png') or file_name.endswith('.jpg'):\n",
    "        # Procesa la imagen que asume hay cara, no fuerza la detección\n",
    "        obj = DeepFace.analyze(img_path = os.path.join(folder, file_name), enforce_detection=False, actions =['age', 'gender', 'race', 'emotion'])\n",
    "        print(file_name)\n",
    "        print(obj[\"region\"])\n",
    "        print(obj[\"age\"])      \n",
    "        print(obj[\"gender\"])      \n",
    "        print(obj[\"race\"])       \n",
    "        print(obj[\"dominant_race\"]) \n",
    "        print(obj[\"emotion\"])\n",
    "        print(obj[\"dominant_emotion\"])\n",
    "       \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'age': 31, 'region': {'x': 249, 'y': 151, 'w': 225, 'h': 225}, 'gender': {'Woman': 0.2272941404953599, 'Man': 99.772709608078}, 'dominant_gender': 'Man', 'race': {'asian': 8.487571775913239, 'indian': 9.421802312135696, 'black': 6.054086238145828, 'white': 27.41501033306122, 'middle eastern': 25.370213389396667, 'latino hispanic': 23.25132042169571}, 'dominant_race': 'white', 'emotion': {'angry': 0.12707079645717698, 'disgust': 8.596284887273444e-06, 'fear': 0.007274600060096763, 'happy': 96.99186050794846, 'sad': 0.0017277338215149279, 'surprise': 0.5369691352658433, 'neutral': 2.3350923311820426}, 'dominant_emotion': 'happy'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'age': 28, 'region': {'x': 245, 'y': 143, 'w': 183, 'h': 183}, 'gender': {'Woman': 0.1841811346821487, 'Man': 99.81581568717957}, 'dominant_gender': 'Man', 'race': {'asian': 1.5521219000220299, 'indian': 2.872201055288315, 'black': 1.7890876159071922, 'white': 57.98468589782715, 'middle eastern': 21.10965847969055, 'latino hispanic': 14.692243933677673}, 'dominant_race': 'white', 'emotion': {'angry': 6.878751325655963e-06, 'disgust': 5.23944491950133e-08, 'fear': 1.1245993905529381e-06, 'happy': 99.84192850089926, 'sad': 7.755877148539794e-05, 'surprise': 0.00010082862835060044, 'neutral': 0.15788278988655927}, 'dominant_emotion': 'happy'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'age': 30, 'region': {'x': 246, 'y': 160, 'w': 143, 'h': 143}, 'gender': {'Woman': 0.5446104798465967, 'Man': 99.45539236068726}, 'dominant_gender': 'Man', 'race': {'asian': 7.325936237089185, 'indian': 8.937084250102549, 'black': 4.463352049988752, 'white': 29.859033806208824, 'middle eastern': 24.776333543817227, 'latino hispanic': 24.6382653282005}, 'dominant_race': 'white', 'emotion': {'angry': 4.743523895740509, 'disgust': 0.020874367328360677, 'fear': 0.5222607869654894, 'happy': 18.39413493871689, 'sad': 0.703028729185462, 'surprise': 0.13912313152104616, 'neutral': 75.47705173492432}, 'dominant_emotion': 'neutral'}]\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow('Webcam', frame)\n",
    "\n",
    "        # Presiona 's' para analizar la cara en el frame actual\n",
    "        if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "            try:\n",
    "                # Análisis de la cara con DeepFace\n",
    "                analysis = DeepFace.analyze(frame, actions = ['age', 'gender', 'race', 'emotion'])\n",
    "                print(analysis)\n",
    "            except Exception as e:\n",
    "                print(\"Error en el análisis:\", e)\n",
    "\n",
    "        # Presiona 'q' para salirq\n",
    "        elif cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b1843aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg_face_weights.h5 will be downloaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://github.com/serengil/deepface_models/releases/download/v1.0/vgg_face_weights.h5\n",
      "To: C:\\Users\\ganma\\.deepface\\weights\\vgg_face_weights.h5\n",
      "100%|██████████| 580M/580M [00:06<00:00, 95.7MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facial recognition model VGG-Face is just built\n",
      "Age model is just built\n",
      "Gender model is just built\n",
      "Emotion model is just built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding representations: 100%|██████████| 16/16 [00:04<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representations stored in ./caritas//representations_vgg_face.pkl file.Please delete this file when you add new identities in your database.\n",
      "find function lasts  4.323499441146851  seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from deepface import DeepFace\n",
    "\n",
    "\n",
    "# Función para iniciar la transmisión y el reconocimiento facial\n",
    "def start_stream(db_path, model_name='VGG-Face', detector_backend = 'opencv', time_threshold = 5, frame_threshold = 5):\n",
    "    \"\"\"\n",
    "    Inicia la transmisión de video y el reconocimiento facial.\n",
    "    db_path: Ruta a la base de datos de imágenes.\n",
    "    model_name: Modelo de reconocimiento facial a utilizar.\n",
    "    detector_backend: Backend de detección de rostros.\n",
    "    time_threshold y frame_threshold: Umbrales para el reconocimiento.\n",
    "    \"\"\"\n",
    "    DeepFace.stream(db_path, model_name = model_name, detector_backend = detector_backend, time_threshold = time_threshold, frame_threshold = frame_threshold)\n",
    "\n",
    "# Especifica la ruta a tu base de datos de imágenes\n",
    "db_path = \"./caritas/\"\n",
    "\n",
    "# Iniciar la transmisión y el reconocimiento facial\n",
    "start_stream(db_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Representations for images in ./caritas/ folder were previously stored in representations_vgg_face.pkl. If you added new instances after the creation, then please delete this file and call find function again. It will create it again.\n",
      "There are  16  representations found in  representations_vgg_face.pkl\n",
      "find function lasts  0.27300071716308594  seconds\n",
      "Persona más parecida: 0    ./caritas/Josete/Josito-2.PNG\n",
      "1    ./caritas/Josete/Josito-3.PNG\n",
      "2        ./caritas/Adri/Adri-3.PNG\n",
      "3        ./caritas/Adri/Adri-2.PNG\n",
      "4        ./caritas/Adri/Adri-1.PNG\n",
      "Name: identity, dtype: object\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ganma\\Documents\\VC\\VC\\P6\\VC_P6_deepface_analyze.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ganma/Documents/VC/VC/P6/VC_P6_deepface_analyze.ipynb#W5sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ganma/Documents/VC/VC/P6/VC_P6_deepface_analyze.ipynb#W5sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError en la búsqueda: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ganma/Documents/VC/VC/P6/VC_P6_deepface_analyze.ipynb#W5sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39melif\u001b[39;00m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m1\u001b[39;49m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ganma/Documents/VC/VC/P6/VC_P6_deepface_analyze.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ganma/Documents/VC/VC/P6/VC_P6_deepface_analyze.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m cap\u001b[39m.\u001b[39mrelease()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imshow('Webcam', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        try:\n",
    "            db_path = \"./caritas/\"\n",
    "            results = DeepFace.find(img_path=frame, db_path=db_path)\n",
    "            \n",
    "            if isinstance(results, list) and len(results) == 0:\n",
    "                print(\"No se encontraron coincidencias.\")\n",
    "            else:\n",
    "                # Procesar los resultados si no es una lista vacía\n",
    "                print(\"Persona más parecida:\", results[0]['identity'])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en la búsqueda: {e}\")\n",
    "\n",
    "    elif cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Representations for images in ../../juegoDeTronos/ folder were previously stored in representations_vgg_face.pkl. If you added new instances after the creation, then please delete this file and call find function again. It will create it again.\n",
      "There are  42  representations found in  representations_vgg_face.pkl\n",
      "find function lasts  0.30299878120422363  seconds\n",
      "WARNING: Representations for images in ../../juegoDeTronos/ folder were previously stored in representations_vgg_face.pkl. If you added new instances after the creation, then please delete this file and call find function again. It will create it again.\n",
      "There are  42  representations found in  representations_vgg_face.pkl\n",
      "find function lasts  0.2889978885650635  seconds\n",
      "WARNING: Representations for images in ../../marvel/ folder were previously stored in representations_vgg_face.pkl. If you added new instances after the creation, then please delete this file and call find function again. It will create it again.\n",
      "There are  36  representations found in  representations_vgg_face.pkl\n",
      "find function lasts  0.2920660972595215  seconds\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "\n",
    "def get_similarity_percentage(cosine_distance):\n",
    "    # Convertir la distancia coseno en un porcentaje de similitud\n",
    "    similarity = max(0, (1 - cosine_distance) * 100)\n",
    "    return similarity\n",
    "\n",
    "# Define los modos y las rutas de las bases de datos\n",
    "modes = {\"Modo 1\": \"../../juegoDeTronos/\", \"Modo 2\": \"../../marvel/\"}\n",
    "current_mode = \"Modo 1\"\n",
    "\n",
    "# Variables globales\n",
    "global_similar_image = None\n",
    "global_similarity_percentage = None\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    h, w, _ = frame.shape\n",
    "\n",
    "    #modo\n",
    "    if cv2.waitKey(1) & 0xFF == ord('m'):\n",
    "        current_mode = \"Modo 1\" if current_mode == \"Modo 2\" else \"Modo 2\"\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        try:\n",
    "            db_path = modes[current_mode]\n",
    "            results = DeepFace.find(img_path=frame, db_path=db_path, enforce_detection=False)\n",
    "\n",
    "            if isinstance(results, list) and results:\n",
    "                top_match = results[0]\n",
    "                similar_image_path = top_match[\"identity\"][0]\n",
    "                cosine_distance = top_match[\"VGG-Face_cosine\"][0]\n",
    "                global_similarity_percentage = get_similarity_percentage(cosine_distance)\n",
    "\n",
    "                global_similar_image = cv2.imread(similar_image_path)\n",
    "                if global_similar_image is not None:\n",
    "                    global_similar_image = cv2.resize(global_similar_image, (w//3, h//3))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en la búsqueda: {e}\")\n",
    "\n",
    "    # Mostrar la imagen más parecida, el porcentaje de similitud y el modo actual\n",
    "    if global_similar_image is not None:\n",
    "        frame[0:h//3, 0:w//3] = global_similar_image\n",
    "        text = f\"Similitud: {global_similarity_percentage:.2f}%\"\n",
    "        cv2.putText(frame, text, (10, h//3), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Mostrar el modo actual\n",
    "    cv2.putText(frame, current_mode, (w - 200, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow('Webcam', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codigo previo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ganma\\Documents\\VC\\VC\\P6\\VC_P6_deepface_analyze.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ganma/Documents/VC/VC/P6/VC_P6_deepface_analyze.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ret:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ganma/Documents/VC/VC/P6/VC_P6_deepface_analyze.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ganma/Documents/VC/VC/P6/VC_P6_deepface_analyze.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m cv2\u001b[39m.\u001b[39;49mimshow(\u001b[39m'\u001b[39;49m\u001b[39mWebcam\u001b[39;49m\u001b[39m'\u001b[39;49m, frame)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ganma/Documents/VC/VC/P6/VC_P6_deepface_analyze.ipynb#X11sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mif\u001b[39;00m cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m1\u001b[39m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39ms\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ganma/Documents/VC/VC/P6/VC_P6_deepface_analyze.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "\n",
    "def get_similarity_percentage(distance):\n",
    "    # Esta función convierte la distancia en un porcentaje de similitud\n",
    "    # Puedes ajustar la fórmula según tus necesidades\n",
    "    similarity = max(0, 100 - distance * 10)\n",
    "    return similarity\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imshow('Webcam', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        try:\n",
    "            db_path = \"./caritas\"  # Ruta a la base de datos de imágenes\n",
    "            results = DeepFace.find(img_path=frame, db_path=db_path, enforce_detection=False)\n",
    "            print(results[0])\n",
    "            if isinstance(results, list) and len(results) > 0:\n",
    "                similar_image_path = results[0]['identity']\n",
    "                similarity_percentage = get_similarity_percentage(results[0]['distance'])\n",
    "\n",
    "                similar_image = cv2.imread(similar_image_path)\n",
    "                if similar_image is not None:\n",
    "                    # Redimensionar la imagen más parecida\n",
    "                    h, w, _ = frame.shape\n",
    "                    similar_image = cv2.resize(similar_image, (w//3, h//3))\n",
    "\n",
    "                    # Superponer la imagen más parecida en el frame de la webcam\n",
    "                    frame[0:h//3, 0:w//3] = similar_image\n",
    "\n",
    "                    # Mostrar el porcentaje de similitud\n",
    "                    text = f\"Similitud: {similarity_percentage:.2f}%\"\n",
    "                    cv2.putText(frame, text, (10, h - 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            cv2.imshow('Webcam + Similar', frame)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en la búsqueda: {e}\")\n",
    "\n",
    "    elif cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Representations for images in ./caritas folder were previously stored in representations_vgg_face.pkl. If you added new instances after the creation, then please delete this file and call find function again. It will create it again.\n",
      "There are  16  representations found in  representations_vgg_face.pkl\n",
      "find function lasts  0.24850082397460938  seconds\n",
      "Resultados: [                        identity  source_x  source_y  source_w  source_h  \\\n",
      "0  ./caritas/Josete/Josito-2.PNG       263       154       221       221   \n",
      "1  ./caritas/Josete/Josito-3.PNG       263       154       221       221   \n",
      "2      ./caritas/Adri/Adri-1.PNG       263       154       221       221   \n",
      "3      ./caritas/Adri/Adri-3.PNG       263       154       221       221   \n",
      "\n",
      "   VGG-Face_cosine  \n",
      "0         0.246356  \n",
      "1         0.263904  \n",
      "2         0.364848  \n",
      "3         0.391669  ]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imshow('Webcam', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        try:\n",
    "            db_path = \"./caritas\"  # Ruta a la base de datos de imágenes\n",
    "            results = DeepFace.find(img_path=frame, db_path=db_path, enforce_detection=False)\n",
    "\n",
    "            # Imprimir la estructura de los resultados para depuración\n",
    "            print(\"Resultados:\", results)\n",
    "            \n",
    "            if isinstance(results, list) and len(results) > 0:\n",
    "                # Aquí procesarás los resultados basado en su estructura real\n",
    "                pass  # Reemplazar con el código correspondiente\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en la búsqueda: {e}\")\n",
    "\n",
    "    elif cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('deepface')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "12028effb1af0cd2244438ff9b17d06bb1d7695ec7a554a144e43ec4b8b79006"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
