{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import math \n",
    "import numpy as np\n",
    "import os\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducción de resolución manteniendo las proporciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video redimensionado guardado como '../../resized_720.mp4'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def resize_video(input_video_path, output_video_path, new_width=None, new_height=None):\n",
    "    # Abre el video original\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "    # Verifica si el video se abrió correctamente\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: No se pudo abrir el video.\")\n",
    "        return\n",
    "\n",
    "    # Obtiene las dimensiones originales del video\n",
    "    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Calcula la nueva resolución manteniendo la proporción\n",
    "    if new_width is not None:\n",
    "        scale_ratio = new_width / original_width\n",
    "        new_height = int(original_height * scale_ratio)\n",
    "    elif new_height is not None:\n",
    "        scale_ratio = new_height / original_height\n",
    "        new_width = int(original_width * scale_ratio)\n",
    "    else:\n",
    "        print(\"Error: Debes especificar un nuevo ancho o un nuevo alto.\")\n",
    "        return\n",
    "\n",
    "    # Propiedades del video de salida\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Formato del codec\n",
    "\n",
    "    # Crea un objeto de escritura de video\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (new_width, new_height))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Si se leyó correctamente el frame\n",
    "        if ret:\n",
    "            # Redimensiona el frame\n",
    "            resized_frame = cv2.resize(frame, (new_width, new_height))\n",
    "            out.write(resized_frame)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Cierra todos los recursos\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(f\"Video redimensionado guardado como '{output_video_path}'\")\n",
    "\n",
    "# Uso de la función especificando solo el nuevo ancho o el nuevo alto\n",
    "resize_video('../../DSC_0047.MOV', '../../resized_720.mp4', new_width=1280)  # Ejemplo con nuevo ancho\n",
    "# resize_video('ruta_del_video_entrada.mp4', 'ruta_del_video_salida.mp4', new_height=480)  # Ejemplo con nuevo alto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para reducir la resolución al máximo aceptable por cuda (hacia abajo, el requisito es que tiene que ser divisible entre 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video redimensionado guardado en ../../stream.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def resize_video(input_path, output_path, stride=32):\n",
    "    # Abre el video original\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error al abrir el video.\")\n",
    "        return\n",
    "\n",
    "    # Obtiene las dimensiones originales del video\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Calcula nuevas dimensiones divisibles por el 'stride'\n",
    "    new_width = width - (width % stride)\n",
    "    new_height = height - (height % stride)\n",
    "\n",
    "    # Obtiene el formato del video y fps\n",
    "    fourcc = int(cap.get(cv2.CAP_PROP_FOURCC))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Crea un objeto de escritura de video con las nuevas dimensiones\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (new_width, new_height))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Redimensiona el frame\n",
    "        resized_frame = cv2.resize(frame, (new_width, new_height))\n",
    "\n",
    "        # Escribe el frame redimensionado en el nuevo video\n",
    "        out.write(resized_frame)\n",
    "\n",
    "    # Libera los recursos\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Video redimensionado guardado en {output_path}\")\n",
    "\n",
    "# Uso de la función\n",
    "input_video_path = '../../resized_720.mp4'  # Ruta al video original\n",
    "output_video_path = '../../stream.mp4'  # Ruta donde se guardará el video redimensionado\n",
    "resize_video(input_video_path, output_video_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para mostrar los FPS de un video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS del video: 59.94\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Función para obtener y mostrar los FPS de un video\n",
    "def print_video_fps(video_path):\n",
    "    # Abre el video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error al abrir el video.\")\n",
    "        return\n",
    "\n",
    "    # Obtiene los FPS del video\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Muestra los FPS\n",
    "    print(f\"FPS del video: {fps}\")\n",
    "\n",
    "    # Libera el objeto de captura\n",
    "    cap.release()\n",
    "\n",
    "# Ruta al video\n",
    "video_path = '../../stream.mp4'  # Reemplaza con la ruta a tu video\n",
    "\n",
    "# Llama a la función\n",
    "print_video_fps(video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para modificar los FPS de un video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS original: 59.94\n",
      "Factor de reducción de frames: 2\n",
      "Video convertido guardado como '../../resized_720_24_fps.mp4'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def convert_video_fps(input_video_path, output_video_path, target_fps):\n",
    "    # Abre el video original\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "    # Verifica si el video se abrió correctamente\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: No se pudo abrir el video.\")\n",
    "        return\n",
    "\n",
    "    # Obtiene los FPS del video original\n",
    "    original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    print(f\"FPS original: {original_fps}\")\n",
    "\n",
    "    # Calcula el factor de reducción de frames\n",
    "    frame_reduction_factor = int(round(original_fps / target_fps))\n",
    "    print(f\"Factor de reducción de frames: {frame_reduction_factor}\")\n",
    "\n",
    "    # Propiedades del video de salida\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Formato del codec\n",
    "\n",
    "    # Crea un objeto de escritura de video\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, target_fps, (width, height))\n",
    "\n",
    "    frame_counter = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Si se leyó correctamente el frame\n",
    "        if ret:\n",
    "            # Escribe el frame según el factor de reducción\n",
    "            if frame_counter % frame_reduction_factor == 0:\n",
    "                out.write(frame)\n",
    "\n",
    "            frame_counter += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Cierra todos los recursos\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(f\"Video convertido guardado como '{output_video_path}'\")\n",
    "\n",
    "# Uso de la función\n",
    "convert_video_fps('../../stream.mp4', '../../resized_720_24_fps.mp4', 24)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modificación de bitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video reducido guardado como '../../stream_bitrate2.mp4' con bitrate de 3M.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "def make_video_lighter(input_video_path, output_video_path, bitrate='1M'):\n",
    "    \"\"\"\n",
    "    Reduce el tamaño de un video ajustando su bitrate.\n",
    "    \n",
    "    Args:\n",
    "    input_video_path (str): Ruta al video de entrada.\n",
    "    output_video_path (str): Ruta donde se guardará el video de salida.\n",
    "    bitrate (str): Bitrate deseado para el video de salida (por ejemplo, '1M' para 1 Mbps).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Comando FFmpeg para ajustar el bitrate\n",
    "        command = [\n",
    "            'ffmpeg', '-i', input_video_path, \n",
    "            '-b:v', bitrate, \n",
    "            '-bufsize', bitrate, \n",
    "            output_video_path\n",
    "        ]\n",
    "\n",
    "        # Ejecutar el comando\n",
    "        subprocess.run(command, check=True)\n",
    "        print(f\"Video reducido guardado como '{output_video_path}' con bitrate de {bitrate}.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error al ejecutar FFmpeg: {e}\")\n",
    "\n",
    "# Uso de la función\n",
    "make_video_lighter('../../resized_720_24_fps.mp4', '../../stream_bitrate2.mp4', '3M') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta ajusta el bitrate y lo deja con el mismo bitrate que el video pasado como primer parámetro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(1739, 1757), match='bitrate: 8579 kb/s'>\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import re\n",
    "\n",
    "def get_bitrate(video_path):\n",
    "    \"\"\"\n",
    "    Obtiene el bitrate de un video usando FFmpeg.\n",
    "    \"\"\"\n",
    "    command = ['ffmpeg', '-i', video_path]\n",
    "    result = subprocess.run(command, stderr=subprocess.PIPE, text=True, check=False)\n",
    "    bitrate_match = re.search(r'bitrate: (\\d+) kb/s', result.stderr)\n",
    "    if bitrate_match:\n",
    "        print(bitrate_match)\n",
    "        return bitrate_match.group(1) + 'k'\n",
    "    else:\n",
    "        raise ValueError(\"No se pudo obtener el bitrate del video\")\n",
    "\n",
    "def make_video_lighter(input_video_path, output_video_path):\n",
    "    \"\"\"\n",
    "    Reduce el tamaño de un video manteniendo su bitrate original.\n",
    "    \n",
    "    Args:\n",
    "    input_video_path (str): Ruta al video de entrada.\n",
    "    output_video_path (str): Ruta donde se guardará el video de salida.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Obtiene el bitrate del video de entrada\n",
    "        bitrate = get_bitrate(input_video_path)\n",
    "\n",
    "        # Comando FFmpeg para ajustar el bitrate\n",
    "        command = [\n",
    "            'ffmpeg', '-i', input_video_path, \n",
    "            '-b:v', bitrate, \n",
    "            '-bufsize', bitrate, \n",
    "            output_video_path\n",
    "        ]\n",
    "\n",
    "        # Ejecutar el comando\n",
    "        subprocess.run(command, check=True)\n",
    "        print(f\"Video procesado guardado como '{output_video_path}' con bitrate de {bitrate}.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error al ejecutar FFmpeg: {e}\")\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "\n",
    "# Uso de la función\n",
    "make_video_lighter('../../stream.mp4', '../../prueba2.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Preparar la imagen para el modelo YOLO\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     img_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(img)\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m---> 24\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m     27\u001b[0m         boxes \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mboxes\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO  # Asegúrate de que la biblioteca de YOLO esté instalada\n",
    "import torch\n",
    "import math\n",
    "\n",
    "# Carga del modelo YOLO y uso de la GPU si está disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = YOLO('./yolov8n.pt').to(device)\n",
    "\n",
    "print(device)\n",
    "\n",
    "# Nombre de las distintas clases (filtrado a vehículos y personas)\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"bus\", \"train\", \"truck\"]\n",
    "\n",
    "# Captura desde un archivo de video\n",
    "vid = cv2.VideoCapture('../../stream_bitrate2.mp4')\n",
    "\n",
    "while(True):\n",
    "    ret, img = vid.read()\n",
    "  \n",
    "    if ret:\n",
    "        # Preparar la imagen para el modelo YOLO\n",
    "        img_tensor = torch.from_numpy(img).to(device).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
    "        results = model(img_tensor, stream=True)\n",
    "\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                cls = int(box.cls[0])\n",
    "                \n",
    "                # Verificar si el índice cls está dentro del rango de classNames\n",
    "                if 0 <= cls < len(classNames):\n",
    "                    class_name = classNames[cls]\n",
    "\n",
    "                    # Determinar el color del contenedor basado en la clase\n",
    "                    if class_name == \"person\":\n",
    "                        color = (255, 0, 0)  # Azul para personas\n",
    "                    else:\n",
    "                        color = (0, 0, 255)  # Rojo para vehículos\n",
    "\n",
    "                    x1, y1, x2, y2 = box.xyxy[0]\n",
    "                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                    \n",
    "                    confidence = math.ceil((box.conf[0]*100))/100\n",
    "\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), color, 3)\n",
    "                    cv2.putText(img, class_name, [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "\n",
    "        cv2.imshow('Video', img)\n",
    "\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente bloque permite la selección manual de una región de interés en un video e imprime las coordenadas de las esquinas superior izquierda e inferior derecha de esta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zona seleccionada: (409, 301) a (1057, 484)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Inicialización de variables globales\n",
    "punto_inicial = None\n",
    "punto_final = None\n",
    "seleccionando = False\n",
    "zona_seleccionada = False\n",
    "\n",
    "def seleccionar_zona(event, x, y, flags, param):\n",
    "    global punto_inicial, punto_final, seleccionando, zona_seleccionada\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        punto_inicial = (x, y)\n",
    "        seleccionando = True\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        punto_final = (x, y)\n",
    "        seleccionando = False\n",
    "        zona_seleccionada = True\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if seleccionando:\n",
    "            punto_final = (x, y)\n",
    "\n",
    "def main(video_path):\n",
    "    global punto_inicial, punto_final, seleccionando, zona_seleccionada\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    cv2.namedWindow(\"Video\")\n",
    "    cv2.setMouseCallback(\"Video\", seleccionar_zona)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if punto_inicial and punto_final:\n",
    "            cv2.rectangle(frame, punto_inicial, punto_final, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Video\", frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == 27:  # Esc para salir\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    if zona_seleccionada:\n",
    "        print(f\"Zona seleccionada: {punto_inicial} a {punto_final}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = '../../stream_bitrate2.mp4'  # Reemplaza con la ruta de tu video\n",
    "    main(video_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez obtenidas las coordenadas de las regiones deseadas, las definimos en el programa para poder utilizar nuestro modelo, en este caso, para contar las personas que se encuentran en las zonas delimitadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "\n",
      "0: 704x1280 7 persons, 9 cars, 2 traffic lights, 8.5ms\n",
      "Speed: 0.0ms preprocess, 8.5ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 11 persons, 8 cars, 1 traffic light, 1 backpack, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 4.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 8 cars, 1 traffic light, 1 backpack, 3 handbags, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 6 persons, 7 cars, 2 traffic lights, 1 backpack, 1 handbag, 11.5ms\n",
      "Speed: 0.0ms preprocess, 11.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 7 cars, 2 traffic lights, 1 backpack, 2 handbags, 7.5ms\n",
      "Speed: 0.0ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 7 cars, 2 traffic lights, 1 backpack, 2 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 4.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 6 persons, 7 cars, 1 traffic light, 1 backpack, 2 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 1.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 7 cars, 1 traffic light, 1 backpack, 2 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 7 cars, 2 traffic lights, 1 backpack, 4 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 7 cars, 1 traffic light, 1 backpack, 5 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 6 cars, 3 traffic lights, 2 backpacks, 4 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 6 cars, 3 traffic lights, 2 backpacks, 4 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 6 cars, 1 traffic light, 1 backpack, 4 handbags, 7.5ms\n",
      "Speed: 0.0ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 6 cars, 1 traffic light, 1 backpack, 2 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 7 cars, 2 traffic lights, 1 backpack, 2 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 5 cars, 2 traffic lights, 1 backpack, 3 handbags, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 10 persons, 7 cars, 3 traffic lights, 1 backpack, 5 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 9 persons, 6 cars, 2 traffic lights, 1 backpack, 4 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 9 persons, 5 cars, 2 traffic lights, 2 backpacks, 5 handbags, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 11 persons, 6 cars, 2 traffic lights, 1 backpack, 4 handbags, 5.5ms\n",
      "Speed: 0.5ms preprocess, 5.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 5 cars, 2 traffic lights, 1 backpack, 4 handbags, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 6 cars, 2 traffic lights, 1 backpack, 3 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 5 cars, 1 traffic light, 2 backpacks, 4 handbags, 5.5ms\n",
      "Speed: 0.5ms preprocess, 5.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 9 persons, 4 cars, 1 traffic light, 2 backpacks, 4 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 4 cars, 1 traffic light, 3 backpacks, 4 handbags, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 9 persons, 4 cars, 2 traffic lights, 3 backpacks, 1 handbag, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 4 cars, 1 traffic light, 3 backpacks, 3 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 4 cars, 1 traffic light, 2 backpacks, 3 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 1 traffic light, 2 backpacks, 6 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 1 traffic light, 1 backpack, 4 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 1 traffic light, 1 backpack, 4 handbags, 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 5 cars, 1 traffic light, 2 backpacks, 4 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 1 traffic light, 2 backpacks, 5 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 1.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 1 traffic light, 1 backpack, 4 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 1 airplane, 1 traffic light, 1 backpack, 2 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 1 traffic light, 1 backpack, 3 handbags, 8.5ms\n",
      "Speed: 0.0ms preprocess, 8.5ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 1 traffic light, 2 backpacks, 3 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 1 traffic light, 1 backpack, 4 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 3 cars, 1 traffic light, 1 backpack, 4 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 3 cars, 1 traffic light, 1 backpack, 4 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 3 cars, 1 traffic light, 2 backpacks, 4 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 3 cars, 1 traffic light, 2 backpacks, 2 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 1 traffic light, 2 backpacks, 2 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 6 persons, 4 cars, 1 traffic light, 2 backpacks, 3 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 3 cars, 2 traffic lights, 2 backpacks, 3 handbags, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 3 cars, 2 traffic lights, 2 backpacks, 1 handbag, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 3 cars, 1 traffic light, 2 backpacks, 1 handbag, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 6 cars, 1 traffic light, 2 backpacks, 2 handbags, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 9 persons, 7 cars, 2 traffic lights, 2 backpacks, 1 handbag, 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 6 cars, 2 traffic lights, 1 bench, 2 backpacks, 2 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 7 cars, 2 traffic lights, 2 backpacks, 3 handbags, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 6 cars, 2 traffic lights, 1 bench, 2 backpacks, 3 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 7 cars, 1 traffic light, 1 bench, 2 backpacks, 3 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 7 cars, 1 traffic light, 1 backpack, 3 handbags, 6.0ms\n",
      "Speed: 0.5ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 6 cars, 1 traffic light, 2 backpacks, 4 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 6 cars, 2 traffic lights, 2 backpacks, 5 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 4.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 6 cars, 1 traffic light, 1 backpack, 5 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 6 cars, 1 traffic light, 1 backpack, 7 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 5 cars, 1 traffic light, 1 backpack, 7 handbags, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 6 cars, 2 traffic lights, 1 backpack, 7 handbags, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 7 cars, 2 traffic lights, 1 backpack, 5 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 7 cars, 2 traffic lights, 1 backpack, 5 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 1.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 5 cars, 2 traffic lights, 2 backpacks, 6 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 6 cars, 2 traffic lights, 1 bench, 1 backpack, 7 handbags, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 5 cars, 2 traffic lights, 1 bench, 1 backpack, 6 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 5 cars, 2 traffic lights, 1 bench, 1 backpack, 5 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 5 cars, 2 traffic lights, 1 backpack, 4 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 5 cars, 2 traffic lights, 1 backpack, 4 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 5 cars, 2 traffic lights, 1 backpack, 3 handbags, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 5 cars, 2 traffic lights, 1 backpack, 4 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 4 cars, 2 traffic lights, 1 backpack, 2 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 1.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 9 persons, 4 cars, 2 traffic lights, 1 backpack, 2 handbags, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 4 cars, 2 traffic lights, 1 backpack, 2 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 2 traffic lights, 1 backpack, 2 handbags, 7.5ms\n",
      "Speed: 0.0ms preprocess, 7.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 4 cars, 2 traffic lights, 1 backpack, 3 handbags, 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 9 persons, 4 cars, 2 traffic lights, 1 backpack, 3 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 4 cars, 2 traffic lights, 1 backpack, 3 handbags, 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 9 persons, 4 cars, 2 traffic lights, 1 backpack, 2 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 9 persons, 4 cars, 2 traffic lights, 1 backpack, 3 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 9 persons, 4 cars, 2 traffic lights, 2 backpacks, 3 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 4 cars, 2 traffic lights, 2 backpacks, 3 handbags, 1 skateboard, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 4 cars, 2 traffic lights, 1 backpack, 4 handbags, 9.0ms\n",
      "Speed: 0.0ms preprocess, 9.0ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 4 cars, 2 traffic lights, 1 dog, 1 backpack, 3 handbags, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 4 cars, 2 traffic lights, 2 backpacks, 4 handbags, 9.5ms\n",
      "Speed: 0.0ms preprocess, 9.5ms inference, 4.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 6 cars, 1 traffic light, 2 backpacks, 3 handbags, 7.5ms\n",
      "Speed: 0.0ms preprocess, 7.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 5 cars, 1 traffic light, 2 backpacks, 3 handbags, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 6 cars, 1 traffic light, 2 backpacks, 4 handbags, 11.0ms\n",
      "Speed: 0.0ms preprocess, 11.0ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 6 cars, 1 traffic light, 2 backpacks, 5 handbags, 9.5ms\n",
      "Speed: 0.0ms preprocess, 9.5ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 6 cars, 1 traffic light, 2 backpacks, 3 handbags, 8.0ms\n",
      "Speed: 0.5ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 6 cars, 1 traffic light, 2 backpacks, 4 handbags, 7.5ms\n",
      "Speed: 0.0ms preprocess, 7.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 6 cars, 1 traffic light, 2 backpacks, 5 handbags, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 6 cars, 1 traffic light, 1 backpack, 5 handbags, 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 6 cars, 1 traffic light, 1 backpack, 6 handbags, 11.0ms\n",
      "Speed: 0.0ms preprocess, 11.0ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 6 cars, 2 traffic lights, 2 backpacks, 6 handbags, 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 6 persons, 7 cars, 3 traffic lights, 1 backpack, 4 handbags, 8.5ms\n",
      "Speed: 0.0ms preprocess, 8.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 7 cars, 3 traffic lights, 1 backpack, 4 handbags, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 7 cars, 3 traffic lights, 1 backpack, 5 handbags, 1 suitcase, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 6 cars, 3 traffic lights, 1 backpack, 5 handbags, 1 suitcase, 11.5ms\n",
      "Speed: 0.0ms preprocess, 11.5ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 7 cars, 3 traffic lights, 1 dog, 1 backpack, 5 handbags, 7.5ms\n",
      "Speed: 0.0ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 7 cars, 3 traffic lights, 1 backpack, 5 handbags, 13.0ms\n",
      "Speed: 0.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 7 cars, 3 traffic lights, 1 dog, 1 backpack, 3 handbags, 1 suitcase, 14.0ms\n",
      "Speed: 0.0ms preprocess, 14.0ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 6 cars, 3 traffic lights, 1 backpack, 3 handbags, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 6 cars, 3 traffic lights, 1 backpack, 5 handbags, 9.0ms\n",
      "Speed: 0.0ms preprocess, 9.0ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 6 cars, 3 traffic lights, 1 backpack, 4 handbags, 7.5ms\n",
      "Speed: 0.0ms preprocess, 7.5ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 6 cars, 3 traffic lights, 1 backpack, 5 handbags, 1 suitcase, 12.0ms\n",
      "Speed: 0.0ms preprocess, 12.0ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 9 persons, 7 cars, 3 traffic lights, 1 backpack, 3 handbags, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 7 cars, 1 traffic light, 1 backpack, 3 handbags, 1 suitcase, 9.0ms\n",
      "Speed: 0.0ms preprocess, 9.0ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 7 cars, 1 traffic light, 1 backpack, 4 handbags, 1 suitcase, 7.5ms\n",
      "Speed: 0.0ms preprocess, 7.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 1 bicycle, 7 cars, 1 traffic light, 1 backpack, 6 handbags, 12.0ms\n",
      "Speed: 0.0ms preprocess, 12.0ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 1 bicycle, 6 cars, 1 traffic light, 1 backpack, 6 handbags, 8.5ms\n",
      "Speed: 0.0ms preprocess, 8.5ms inference, 4.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 1 bicycle, 6 cars, 1 truck, 1 traffic light, 1 backpack, 6 handbags, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 1 bicycle, 5 cars, 1 truck, 1 traffic light, 1 backpack, 1 umbrella, 6 handbags, 1 suitcase, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 5 cars, 2 trucks, 1 traffic light, 1 backpack, 4 handbags, 1 suitcase, 7.5ms\n",
      "Speed: 0.0ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 2 trucks, 2 traffic lights, 1 backpack, 3 handbags, 11.5ms\n",
      "Speed: 0.0ms preprocess, 11.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 5 persons, 5 cars, 1 truck, 2 traffic lights, 1 backpack, 2 handbags, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 6 persons, 5 cars, 1 truck, 2 traffic lights, 1 backpack, 3 handbags, 8.5ms\n",
      "Speed: 0.0ms preprocess, 8.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 6 persons, 5 cars, 1 truck, 2 traffic lights, 1 backpack, 2 handbags, 1 suitcase, 8.5ms\n",
      "Speed: 0.0ms preprocess, 8.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 6 persons, 5 cars, 1 truck, 1 traffic light, 1 backpack, 2 handbags, 1 suitcase, 11.5ms\n",
      "Speed: 0.0ms preprocess, 11.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 5 cars, 1 traffic light, 1 backpack, 2 handbags, 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 5 persons, 5 cars, 2 traffic lights, 1 backpack, 2 handbags, 10.5ms\n",
      "Speed: 0.0ms preprocess, 10.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 5 persons, 5 cars, 2 traffic lights, 1 backpack, 2 handbags, 8.5ms\n",
      "Speed: 0.0ms preprocess, 8.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 6 persons, 5 cars, 2 traffic lights, 1 backpack, 2 handbags, 11.0ms\n",
      "Speed: 0.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 5 cars, 2 traffic lights, 1 backpack, 2 handbags, 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 5 cars, 2 traffic lights, 2 backpacks, 1 handbag, 11.0ms\n",
      "Speed: 0.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 6 cars, 2 traffic lights, 2 backpacks, 1 handbag, 10.5ms\n",
      "Speed: 0.0ms preprocess, 10.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 7 cars, 1 truck, 1 traffic light, 2 backpacks, 1 handbag, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 4.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 8 cars, 3 traffic lights, 2 backpacks, 1 handbag, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 5.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 8 cars, 3 traffic lights, 2 backpacks, 1 handbag, 9.5ms\n",
      "Speed: 0.5ms preprocess, 9.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 10 cars, 3 traffic lights, 2 backpacks, 1 handbag, 1 suitcase, 12.5ms\n",
      "Speed: 0.0ms preprocess, 12.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 8 cars, 2 traffic lights, 2 backpacks, 1 handbag, 12.5ms\n",
      "Speed: 0.0ms preprocess, 12.5ms inference, 4.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 8 cars, 3 traffic lights, 2 backpacks, 1 handbag, 9.5ms\n",
      "Speed: 0.0ms preprocess, 9.5ms inference, 5.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 10 cars, 3 traffic lights, 2 backpacks, 1 handbag, 9.0ms\n",
      "Speed: 0.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 9 cars, 2 traffic lights, 2 backpacks, 1 handbag, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 10 cars, 2 traffic lights, 2 backpacks, 1 handbag, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 10 cars, 2 traffic lights, 2 backpacks, 1 handbag, 9.5ms\n",
      "Speed: 0.0ms preprocess, 9.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 6 persons, 11 cars, 2 traffic lights, 2 backpacks, 1 handbag, 13.0ms\n",
      "Speed: 0.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 6 persons, 10 cars, 2 traffic lights, 2 backpacks, 1 handbag, 12.5ms\n",
      "Speed: 0.0ms preprocess, 12.5ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 6 persons, 9 cars, 1 traffic light, 2 backpacks, 1 handbag, 8.5ms\n",
      "Speed: 0.0ms preprocess, 8.5ms inference, 4.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 5 persons, 9 cars, 1 traffic light, 2 backpacks, 2 handbags, 8.5ms\n",
      "Speed: 0.0ms preprocess, 8.5ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 6 persons, 8 cars, 1 traffic light, 2 backpacks, 1 handbag, 10.5ms\n",
      "Speed: 0.0ms preprocess, 10.5ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 6 persons, 8 cars, 1 traffic light, 3 backpacks, 2 handbags, 10.5ms\n",
      "Speed: 0.0ms preprocess, 10.5ms inference, 4.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 5 persons, 8 cars, 1 traffic light, 1 parking meter, 1 backpack, 1 handbag, 8.5ms\n",
      "Speed: 0.0ms preprocess, 8.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 7 cars, 2 traffic lights, 2 backpacks, 1 handbag, 9.5ms\n",
      "Speed: 0.0ms preprocess, 9.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 5 persons, 7 cars, 1 traffic light, 1 backpack, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 4.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 6 cars, 1 motorcycle, 2 traffic lights, 1 backpack, 9.0ms\n",
      "Speed: 0.0ms preprocess, 9.0ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 2 traffic lights, 2 backpacks, 8.0ms\n",
      "Speed: 0.5ms preprocess, 8.0ms inference, 4.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 1 truck, 2 traffic lights, 1 backpack, 2 handbags, 14.0ms\n",
      "Speed: 0.0ms preprocess, 14.0ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 2 traffic lights, 1 backpack, 11.5ms\n",
      "Speed: 0.0ms preprocess, 11.5ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 2 traffic lights, 1 backpack, 1 handbag, 11.0ms\n",
      "Speed: 0.0ms preprocess, 11.0ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 2 traffic lights, 1 backpack, 8.5ms\n",
      "Speed: 0.0ms preprocess, 8.5ms inference, 4.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 2 traffic lights, 2 backpacks, 8.5ms\n",
      "Speed: 0.0ms preprocess, 8.5ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 5 cars, 2 traffic lights, 3 backpacks, 1 handbag, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 5.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 5 cars, 3 traffic lights, 3 backpacks, 1 handbag, 12.5ms\n",
      "Speed: 0.0ms preprocess, 12.5ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 5 cars, 2 traffic lights, 3 backpacks, 14.5ms\n",
      "Speed: 0.0ms preprocess, 14.5ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 6 cars, 2 traffic lights, 3 backpacks, 13.0ms\n",
      "Speed: 0.0ms preprocess, 13.0ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 4 cars, 2 traffic lights, 3 backpacks, 9.5ms\n",
      "Speed: 0.0ms preprocess, 9.5ms inference, 4.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 6 cars, 2 traffic lights, 2 backpacks, 8.5ms\n",
      "Speed: 0.0ms preprocess, 8.5ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 9 persons, 7 cars, 2 traffic lights, 3 backpacks, 1 handbag, 11.0ms\n",
      "Speed: 0.0ms preprocess, 11.0ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 6 cars, 2 traffic lights, 3 backpacks, 1 handbag, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 4.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 5 cars, 2 traffic lights, 3 backpacks, 1 handbag, 9.0ms\n",
      "Speed: 0.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 5 cars, 3 traffic lights, 4 backpacks, 1 handbag, 11.5ms\n",
      "Speed: 0.0ms preprocess, 11.5ms inference, 5.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 6 persons, 5 cars, 1 traffic light, 4 backpacks, 1 handbag, 9.0ms\n",
      "Speed: 0.0ms preprocess, 9.0ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 6 persons, 5 cars, 2 traffic lights, 3 backpacks, 9.0ms\n",
      "Speed: 0.0ms preprocess, 9.0ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 5 cars, 2 traffic lights, 3 backpacks, 9.5ms\n",
      "Speed: 0.0ms preprocess, 9.5ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 5 cars, 3 traffic lights, 1 fire hydrant, 3 backpacks, 1 handbag, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 5 cars, 2 traffic lights, 3 backpacks, 1 handbag, 9.0ms\n",
      "Speed: 0.0ms preprocess, 9.0ms inference, 4.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 5 cars, 3 traffic lights, 5 backpacks, 2 handbags, 13.5ms\n",
      "Speed: 0.0ms preprocess, 13.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 5 cars, 3 traffic lights, 4 backpacks, 3 handbags, 8.5ms\n",
      "Speed: 0.0ms preprocess, 8.5ms inference, 4.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 5 cars, 2 traffic lights, 4 backpacks, 3 handbags, 8.5ms\n",
      "Speed: 0.5ms preprocess, 8.5ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 5 cars, 2 traffic lights, 3 backpacks, 3 handbags, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 4.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 6 cars, 1 traffic light, 2 backpacks, 4 handbags, 9.0ms\n",
      "Speed: 0.0ms preprocess, 9.0ms inference, 4.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 2 trucks, 1 traffic light, 2 backpacks, 3 handbags, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 1 truck, 1 traffic light, 2 backpacks, 3 handbags, 12.5ms\n",
      "Speed: 0.0ms preprocess, 12.5ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 6 persons, 4 cars, 1 traffic light, 2 backpacks, 3 handbags, 12.0ms\n",
      "Speed: 0.0ms preprocess, 12.0ms inference, 4.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 1 traffic light, 2 backpacks, 3 handbags, 8.5ms\n",
      "Speed: 0.0ms preprocess, 8.5ms inference, 5.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 6 persons, 4 cars, 1 traffic light, 2 backpacks, 3 handbags, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 5 persons, 4 cars, 1 traffic light, 2 backpacks, 3 handbags, 8.5ms\n",
      "Speed: 0.0ms preprocess, 8.5ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 5 persons, 6 cars, 1 traffic light, 3 backpacks, 3 handbags, 17.5ms\n",
      "Speed: 0.0ms preprocess, 17.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 5 persons, 4 cars, 2 traffic lights, 2 backpacks, 3 handbags, 9.5ms\n",
      "Speed: 0.0ms preprocess, 9.5ms inference, 5.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 5 persons, 6 cars, 1 traffic light, 2 backpacks, 3 handbags, 8.5ms\n",
      "Speed: 0.0ms preprocess, 8.5ms inference, 4.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 5 persons, 5 cars, 1 traffic light, 2 backpacks, 3 handbags, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 5 persons, 5 cars, 1 traffic light, 2 backpacks, 3 handbags, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 5.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 5 persons, 5 cars, 1 traffic light, 2 backpacks, 2 handbags, 11.0ms\n",
      "Speed: 0.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 6 cars, 3 traffic lights, 2 backpacks, 1 handbag, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 4.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 5 cars, 2 traffic lights, 1 backpack, 2 handbags, 12.5ms\n",
      "Speed: 0.0ms preprocess, 12.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 1 traffic light, 1 backpack, 2 handbags, 196.0ms\n",
      "Speed: 0.0ms preprocess, 196.0ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 1 traffic light, 1 backpack, 2 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 6 cars, 1 traffic light, 1 backpack, 1 handbag, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 6 persons, 8 cars, 1 traffic light, 1 backpack, 1 handbag, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 1.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 6 cars, 1 traffic light, 1 backpack, 1 handbag, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 7 cars, 1 traffic light, 2 backpacks, 1 handbag, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 4.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 8 cars, 1 traffic light, 2 backpacks, 1 handbag, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 9 cars, 1 traffic light, 2 backpacks, 1 handbag, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 6 persons, 8 cars, 1 traffic light, 1 backpack, 1 handbag, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import math\n",
    "\n",
    "def hay_interseccion(caja1, caja2):\n",
    "    x1_max = max(caja1[0], caja2[0])\n",
    "    y1_max = max(caja1[1], caja2[1])\n",
    "    x2_min = min(caja1[2], caja2[2])\n",
    "    y2_min = min(caja1[3], caja2[3])\n",
    "    return x1_max < x2_min and y1_max < y2_min\n",
    "\n",
    "# Carga del modelo YOLO y uso de la GPU si está disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = YOLO('yolov8n.pt').to(device)\n",
    "\n",
    "print(device)\n",
    "\n",
    "# Nombre de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"bus\", \"train\", \"truck\"]\n",
    "\n",
    "# Captura desde un archivo de video\n",
    "vid = cv2.VideoCapture('../../stream_bitrate2.mp4')\n",
    "\n",
    "# Definir la zonas delimitadas (x1, y1, x2, y2)\n",
    "zona_delimitada = (2, 336, 289, 435)\n",
    "zona_delimitada2= (846, 518, 1259, 683)\n",
    "\n",
    "while True:\n",
    "    ret, img = vid.read()\n",
    "    contador_personas = 0  # Inicializar el contador de personas en cada frame\n",
    "\n",
    "    if ret:\n",
    "        # Preparar la imagen para el modelo YOLO\n",
    "        img_tensor = torch.from_numpy(img).to(device).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
    "        results = model(img_tensor, stream=True)\n",
    "\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                cls = int(box.cls[0])\n",
    "\n",
    "                # Índice 0 corresponde a 'person', índice 2 a 'car' (esto puede variar)\n",
    "                if cls in [0, 2]: \n",
    "                    x1, y1, x2, y2 = [int(i) for i in box.xyxy[0]]\n",
    "                    confidence = math.ceil((box.conf[0]*100))/100\n",
    "\n",
    "                    caja_objeto = (x1, y1, x2, y2)\n",
    "\n",
    "                    if hay_interseccion(caja_objeto, zona_delimitada) or hay_interseccion(caja_objeto, zona_delimitada2):\n",
    "                        color = (0, 255, 0)  # Verde si está dentro de alguna de las zonas\n",
    "                        if cls == 0:  # Si es persona\n",
    "                            contador_personas += 1\n",
    "                    else:\n",
    "                        if cls == 0:\n",
    "                            color = (255, 0, 0)  # Azul si está fuera de ambas zonas\n",
    "                        else:\n",
    "                            color = (0,0,255)\n",
    "\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), color, 3)\n",
    "                    etiqueta = classNames[cls] if cls < len(classNames) else 'Unknown'\n",
    "                    cv2.putText(img, f'{etiqueta}: {confidence}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        # Dibuja la zona delimitada\n",
    "        cv2.rectangle(img, zona_delimitada[:2], zona_delimitada[2:], (255, 255, 255), 2)\n",
    "        cv2.rectangle(img, zona_delimitada2[:2], zona_delimitada2[2:], (255, 255, 255), 2)\n",
    "\n",
    "        # Mostrar el número de personas en la zona delimitada\n",
    "        texto_contador = f'Personas en zona: {contador_personas}'\n",
    "        cv2.putText(img, texto_contador, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('Video', img)\n",
    "\n",
    "        if cv2.waitKey(20) == 27:  # Presiona 'Esc' para salir\n",
    "            break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "\n",
      "0: 704x1280 7 persons, 9 cars, 2 traffic lights, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 11 persons, 8 cars, 1 traffic light, 1 backpack, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 4.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 8 cars, 1 traffic light, 1 backpack, 3 handbags, 7.5ms\n",
      "Speed: 0.0ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 6 persons, 7 cars, 2 traffic lights, 1 backpack, 1 handbag, 11.0ms\n",
      "Speed: 0.0ms preprocess, 11.0ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 7 cars, 2 traffic lights, 1 backpack, 2 handbags, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 7 cars, 2 traffic lights, 1 backpack, 2 handbags, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 6 persons, 7 cars, 1 traffic light, 1 backpack, 2 handbags, 8.5ms\n",
      "Speed: 0.0ms preprocess, 8.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 7 cars, 1 traffic light, 1 backpack, 2 handbags, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 7 cars, 2 traffic lights, 1 backpack, 4 handbags, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 7 cars, 1 traffic light, 1 backpack, 5 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 6 cars, 3 traffic lights, 2 backpacks, 4 handbags, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 6 cars, 3 traffic lights, 2 backpacks, 4 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 6 cars, 1 traffic light, 1 backpack, 4 handbags, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 6 cars, 1 traffic light, 1 backpack, 2 handbags, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 7 cars, 2 traffic lights, 1 backpack, 2 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 5 cars, 2 traffic lights, 1 backpack, 3 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 1.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 10 persons, 7 cars, 3 traffic lights, 1 backpack, 5 handbags, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 9 persons, 6 cars, 2 traffic lights, 1 backpack, 4 handbags, 5.5ms\n",
      "Speed: 0.5ms preprocess, 5.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 9 persons, 5 cars, 2 traffic lights, 2 backpacks, 5 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 11 persons, 6 cars, 2 traffic lights, 1 backpack, 4 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 5 cars, 2 traffic lights, 1 backpack, 4 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 6 cars, 2 traffic lights, 1 backpack, 3 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 5 cars, 1 traffic light, 2 backpacks, 4 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 9 persons, 4 cars, 1 traffic light, 2 backpacks, 4 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 4 cars, 1 traffic light, 3 backpacks, 4 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 9 persons, 4 cars, 2 traffic lights, 3 backpacks, 1 handbag, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 4 cars, 1 traffic light, 3 backpacks, 3 handbags, 7.5ms\n",
      "Speed: 0.0ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 8 persons, 4 cars, 1 traffic light, 2 backpacks, 3 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 1 traffic light, 2 backpacks, 6 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 1 traffic light, 1 backpack, 4 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 1 traffic light, 1 backpack, 4 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 5 cars, 1 traffic light, 2 backpacks, 4 handbags, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 1 traffic light, 2 backpacks, 5 handbags, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 1 traffic light, 1 backpack, 4 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 1 airplane, 1 traffic light, 1 backpack, 2 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 1.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 1 traffic light, 1 backpack, 3 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 1 traffic light, 2 backpacks, 3 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 1 traffic light, 1 backpack, 4 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 3 cars, 1 traffic light, 1 backpack, 4 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 1.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 3 cars, 1 traffic light, 1 backpack, 4 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 3 cars, 1 traffic light, 2 backpacks, 4 handbags, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 3 cars, 1 traffic light, 2 backpacks, 2 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 1280)\n",
      "\n",
      "0: 704x1280 7 persons, 4 cars, 1 traffic light, 2 backpacks, 2 handbags, 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 1280)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import math\n",
    "\n",
    "def hay_interseccion(caja1, caja2):\n",
    "    x1_max = max(caja1[0], caja2[0])\n",
    "    y1_max = max(caja1[1], caja2[1])\n",
    "    x2_min = min(caja1[2], caja2[2])\n",
    "    y2_min = min(caja1[3], caja2[3])\n",
    "    return x1_max < x2_min and y1_max < y2_min\n",
    "\n",
    "# Carga del modelo YOLO y uso de la GPU si está disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = YOLO('yolov8n.pt').to(device)\n",
    "\n",
    "print(device)\n",
    "\n",
    "# Nombre de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"bus\", \"train\", \"truck\"]\n",
    "\n",
    "# Captura desde un archivo de video\n",
    "vid = cv2.VideoCapture('../../stream_bitrate2.mp4')\n",
    "\n",
    "# Definir la zona delimitada (x1, y1, x2, y2)\n",
    "zona_delimitada = (805, 483, 1101, 618)\n",
    "\n",
    "while True:\n",
    "    ret, img = vid.read()\n",
    "    contador_personas = 0  # Inicializar el contador de personas en cada frame\n",
    "\n",
    "    if ret:\n",
    "        # Preparar la imagen para el modelo YOLO\n",
    "        img_tensor = torch.from_numpy(img).to(device).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
    "        results = model(img_tensor, stream=True)\n",
    "\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                cls = int(box.cls[0])\n",
    "\n",
    "                # Índice 0 corresponde a 'person', índice 2 a 'car' (esto puede variar)\n",
    "                if cls in [0, 2]: \n",
    "                    x1, y1, x2, y2 = [int(i) for i in box.xyxy[0]]\n",
    "                    confidence = math.ceil((box.conf[0]*100))/100\n",
    "\n",
    "                    caja_objeto = (x1, y1, x2, y2)\n",
    "\n",
    "                    if hay_interseccion(caja_objeto, zona_delimitada):\n",
    "                        color = (0, 255, 0)  # Verde si está dentro de la zona\n",
    "                        if cls == 0:  # Si es persona\n",
    "                            contador_personas += 1\n",
    "                    else:\n",
    "                        if cls == 0:\n",
    "                            color = (255, 0, 0)  # Azul si está fuera de la zona\n",
    "                        else:\n",
    "                            color = (0,0,255)\n",
    "\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), color, 3)\n",
    "                    etiqueta = classNames[cls] if cls < len(classNames) else 'Unknown'\n",
    "                    cv2.putText(img, f'{etiqueta}: {confidence}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        # Dibuja la zona delimitada\n",
    "        cv2.rectangle(img, zona_delimitada[:2], zona_delimitada[2:], (255, 255, 255), 2)\n",
    "\n",
    "        # Mostrar el número de personas en la zona delimitada\n",
    "        texto_contador = f'Personas en zona: {contador_personas}'\n",
    "        cv2.putText(img, texto_contador, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('Video', img)\n",
    "\n",
    "        if cv2.waitKey(20) == 27:  # Presiona 'Esc' para salir\n",
    "            break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro intento, esta vez con vehículos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# Preparar la imagen para el modelo YOLO\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     img_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(img)\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m---> 37\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m     40\u001b[0m         boxes \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mboxes\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import math\n",
    "\n",
    "def hay_interseccion(caja1, caja2):\n",
    "    x1_max = max(caja1[0], caja2[0])\n",
    "    y1_max = max(caja1[1], caja2[1])\n",
    "    x2_min = min(caja1[2], caja2[2])\n",
    "    y2_min = min(caja1[3], caja2[3])\n",
    "    return x1_max < x2_min and y1_max < y2_min\n",
    "\n",
    "# Carga del modelo YOLO y uso de la GPU si está disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = YOLO('yolov8n.pt').to(device)\n",
    "\n",
    "print(device)\n",
    "\n",
    "# Nombre de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"bus\", \"truck\"]\n",
    "\n",
    "# Captura desde un archivo de video\n",
    "vid = cv2.VideoCapture('../../stream_bitrate2.mp4')\n",
    "\n",
    "# Definir la zona delimitada (x1, y1, x2, y2)\n",
    "zona_personas = (805, 483, 1101, 618)\n",
    "zona_vehiculos = (598,314,1132,418)\n",
    "\n",
    "while True:\n",
    "    ret, img = vid.read()\n",
    "    contador_personas = 0  # Inicializar el contador de personas en cada frame\n",
    "    contador_vehiculos = 0\n",
    "\n",
    "    if ret:\n",
    "        # Preparar la imagen para el modelo YOLO\n",
    "        img_tensor = torch.from_numpy(img).to(device).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
    "        results = model(img_tensor, stream=True)\n",
    "\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                cls = int(box.cls[0])\n",
    "\n",
    "                if cls in [0,1,2,3,4,5]: \n",
    "                    x1, y1, x2, y2 = [int(i) for i in box.xyxy[0]]\n",
    "                    confidence = math.ceil((box.conf[0]*100))/100\n",
    "\n",
    "                    caja_objeto = (x1, y1, x2, y2)\n",
    "\n",
    "                    if cls == 0 and hay_interseccion(caja_objeto, zona_personas):\n",
    "                        color = (0, 255, 0)  # Verde si está dentro de la zona\n",
    "                        if cls == 0:  # Si es persona\n",
    "                            contador_personas += 1\n",
    "\n",
    "                    elif cls != 0 and hay_interseccion(caja_objeto, zona_vehiculos):\n",
    "                        color = (255,255,0)\n",
    "                        contador_vehiculos +=1\n",
    "\n",
    "                    else:\n",
    "                        if cls == 0:\n",
    "                            color = (255, 0, 0)  # Azul si está fuera de la zona\n",
    "                        else:\n",
    "                            color = (0,0,255)\n",
    "                    \"\"\" \n",
    "                    if hay_interseccion(caja_objeto, zona_delimitada):\n",
    "                        color = (0, 255, 0)  # Verde si está dentro de la zona\n",
    "                        if cls == 0:  # Si es persona\n",
    "                            contador_personas += 1\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), color, 3)\n",
    "                    etiqueta = classNames[cls] if cls < len(classNames) else 'Unknown'\n",
    "                    cv2.putText(img, f'{etiqueta}: {confidence}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        # Dibuja la zona delimitada\n",
    "        cv2.rectangle(img, zona_personas[:2], zona_personas[2:], (255, 255, 255), 2)\n",
    "        cv2.rectangle(img, zona_vehiculos[:2], zona_vehiculos[2:], (255, 255, 255), 2)\n",
    "        # Mostrar el número de personas en la zona delimitada\n",
    "        texto_contador = f'Personas en zona: {contador_personas}'\n",
    "        cv2.putText(img, texto_contador, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Mostrar el número de vehículos en la zona delimitada\n",
    "        texto_contador = f'Vehiculos en zona: {contador_vehiculos}'\n",
    "        cv2.putText(img, texto_contador, (25, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('Video', img)\n",
    "\n",
    "        if cv2.waitKey(20) == 27:  # Presiona 'Esc' para salir\n",
    "            break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('yolov7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54711ba1bddc392d48ca20e80feaa9b2e23d43069aa8b98ed16355091034ff6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
