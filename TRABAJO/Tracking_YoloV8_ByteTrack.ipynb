{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "488f589d",
   "metadata": {},
   "source": [
    "# Tracking de objetos con YoloV8 y Bytetrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfd964d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ultralytics==8.0.84\n",
    "# !pip install Cython\n",
    "# !pip install numpy\n",
    "# !pip install lap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d659ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# esto es para evitar un error en Windows: OMP: Error #15: Initializing libiomp5md.dll, but found libiomp5md.dll already initialized.\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics.nn.autobackend import AutoBackend\n",
    "from ultralytics.yolo.utils.plotting import Annotator, colors\n",
    "import torch\n",
    "from bytetrack.byte_tracker import BYTETracker\n",
    "from ultralytics.yolo.data.dataloaders.stream_loaders import LoadImages\n",
    "from ultralytics.yolo.utils.ops import non_max_suppression, scale_boxes\n",
    "import time\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80a7ae4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3439399",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_thres = 0.25\n",
    "iou_thres = 0.45\n",
    "classes = None\n",
    "agnostic_nms = False\n",
    "max_det = 1000\n",
    "line_thickness = 2\n",
    "half = False\n",
    "imgsz = (1280, 704)\n",
    "vid_stride = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcad7b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_vid = True\n",
    "video_file = \"../../stream_bitrate2.mp4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d71d22f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "# Verificar si CUDA (GPU) está disponible y luego seleccionar el dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Usando dispositivo:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ac7c665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "model = AutoBackend(\"yolov8n.pt\").to(device)\n",
    "model.warmup()\n",
    "stride, names, pt = model.stride, model.names, model.pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69ea3da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bytetracker = BYTETracker(\n",
    "    track_thresh=0.6, match_thresh=0.8, track_buffer=120, frame_rate=30\n",
    ")\n",
    "tracker = bytetracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69b9178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LoadImages(\n",
    "    video_file,\n",
    "    imgsz=imgsz,\n",
    "    stride=stride,\n",
    "    auto=pt,\n",
    "    transforms=None,\n",
    "    vid_stride=vid_stride,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f033a4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "zona_personas = (805, 483, 1101, 618)\n",
    "\n",
    "tiempos_deteccion = {}\n",
    "\n",
    "def interseccion_zona(bbox, zona):\n",
    "    \"\"\" Verifica si la caja delimitadora (bbox) se cruza con la zona definida. \"\"\"\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    zx1, zy1, zx2, zy2 = zona\n",
    "    return not (x2 < zx1 or x1 > zx2 or y2 < zy1 or y1 > zy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c8962e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame_idx, batch in enumerate(dataset):\n",
    "    tiempo_actual = time.time()\n",
    "    path, im, im0s, vid_cap, s = batch\n",
    "    detections = np.empty((0, 5))\n",
    "    # Asegurarse de que los datos de entrada (imágenes) también estén en la GPU\n",
    "    im = torch.from_numpy(im).to(device)\n",
    "    im = im.half() if half else im.float()  # uint8 to fp16/32\n",
    "    im /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "    im = torch.unsqueeze(im, 0)\n",
    "\n",
    "    result = model(im)\n",
    "\n",
    "    p = non_max_suppression(\n",
    "        result, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det\n",
    "    )\n",
    "\n",
    "    for i, det in enumerate(p):\n",
    "        p, im0, _ = path, im0s.copy(), getattr(dataset, \"frame\", 0)\n",
    "\n",
    "        if det is not None and len(det):\n",
    "            det[:, :4] = scale_boxes(\n",
    "                im.shape[2:], det[:, :4], im0.shape\n",
    "            ).round()  # rescale boxes to im0 size\n",
    "\n",
    "        track_result = tracker.update(det.cpu(), im0)\n",
    "\n",
    "        annotator = Annotator(im0, line_width=line_thickness, example=str(names))\n",
    "\n",
    "        # draw boxes for visualization\n",
    "        if len(track_result) > 0:\n",
    "            for j, (output) in enumerate(track_result):\n",
    "                bbox = output[0:4]\n",
    "                id = output[4]\n",
    "                cls = output[5]\n",
    "                conf = output[6]\n",
    "\n",
    "                c = int(cls)  # integer class\n",
    "                id = int(id)  # integer id\n",
    "                #label = f\"{id} {names[c]} {conf:.2f}\"\n",
    "\n",
    "                if id not in tiempos_deteccion:\n",
    "                    tiempos_deteccion[id] = tiempo_actual\n",
    "\n",
    "                tiempo_deteccion = tiempo_actual - tiempos_deteccion[id]\n",
    "\n",
    "                c = int(cls)  # integer class\n",
    "                label = f\"{id} {names[c]} {tiempo_deteccion:.2f}s\" \n",
    "\n",
    "                if interseccion_zona(bbox, zona_personas):\n",
    "                    color_especial = (0, 255, 0)  # Color verde, por ejemplo\n",
    "                    annotator.box_label(bbox, label, color=color_especial)\n",
    "                else:\n",
    "                    color = colors(c, True)\n",
    "                    annotator.box_label(bbox, label, color=color)\n",
    "\n",
    "                \"\"\" \n",
    "                color = colors(c, True)\n",
    "                annotator.box_label(bbox, label, color=color)\n",
    "                \"\"\"\n",
    "                \n",
    "\n",
    "    # Stream results\n",
    "    im0 = annotator.result()\n",
    "    cv2.imshow(str(p), im0)\n",
    "    if cv2.waitKey(20) == 27:  # Presiona 'Esc' para salir\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0476972",
   "metadata": {},
   "source": [
    "Guardar el video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "312f49c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_vid = True\n",
    "video_file = \"../../stream_bitrate2.mp4\"\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # codec\n",
    "fps = 24  # Asumiendo 30 fps, ajusta según tu video\n",
    "save_path = '../../output.mp4'\n",
    "vid_writer = cv2.VideoWriter(save_path, fourcc, fps, (1280, 704))  # Ajusta la resolución según sea necesario\n",
    "\n",
    "\n",
    "for frame_idx, batch in enumerate(dataset):\n",
    "    tiempo_actual = time.time()\n",
    "    path, im, im0s, vid_cap, s = batch\n",
    "    detections = np.empty((0, 5))\n",
    "    # Asegurarse de que los datos de entrada (imágenes) también estén en la GPU\n",
    "    im = torch.from_numpy(im).to(device)\n",
    "    im = im.half() if half else im.float()  # uint8 to fp16/32\n",
    "    im /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "    im = torch.unsqueeze(im, 0)\n",
    "\n",
    "    result = model(im)\n",
    "\n",
    "    p = non_max_suppression(\n",
    "        result, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det\n",
    "    )\n",
    "\n",
    "    for i, det in enumerate(p):\n",
    "        p, im0, _ = path, im0s.copy(), getattr(dataset, \"frame\", 0)\n",
    "\n",
    "        if det is not None and len(det):\n",
    "            det[:, :4] = scale_boxes(\n",
    "                im.shape[2:], det[:, :4], im0.shape\n",
    "            ).round()  # rescale boxes to im0 size\n",
    "\n",
    "        track_result = tracker.update(det.cpu(), im0)\n",
    "\n",
    "        annotator = Annotator(im0, line_width=line_thickness, example=str(names))\n",
    "\n",
    "        # draw boxes for visualization\n",
    "        if len(track_result) > 0:\n",
    "            for j, (output) in enumerate(track_result):\n",
    "                bbox = output[0:4]\n",
    "                id = output[4]\n",
    "                cls = output[5]\n",
    "                conf = output[6]\n",
    "\n",
    "                c = int(cls)  # integer class\n",
    "                id = int(id)  # integer id\n",
    "                #label = f\"{id} {names[c]} {conf:.2f}\"\n",
    "\n",
    "                if id not in tiempos_deteccion:\n",
    "                    tiempos_deteccion[id] = tiempo_actual\n",
    "\n",
    "                tiempo_deteccion = tiempo_actual - tiempos_deteccion[id]\n",
    "\n",
    "                c = int(cls)  # integer class\n",
    "                label = f\"{id} {names[c]} {tiempo_deteccion:.2f}s\" \n",
    "\n",
    "                if interseccion_zona(bbox, zona_personas):\n",
    "                    color_especial = (0, 255, 0)  # Color verde, por ejemplo\n",
    "                    annotator.box_label(bbox, label, color=color_especial)\n",
    "                else:\n",
    "                    color = colors(c, True)\n",
    "                    annotator.box_label(bbox, label, color=color)\n",
    "\n",
    "                \"\"\" \n",
    "                color = colors(c, True)\n",
    "                annotator.box_label(bbox, label, color=color)\n",
    "                \"\"\"\n",
    "                \n",
    "\n",
    "    # Save results\n",
    "    im0 = annotator.result()\n",
    "    vid_writer.write(im0)\n",
    "\n",
    "\n",
    "\n",
    "vid_writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
