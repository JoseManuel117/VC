{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "488f589d",
   "metadata": {},
   "source": [
    "# Tracking de objetos con YoloV8 y Bytetrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfd964d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ultralytics==8.0.84\n",
    "# !pip install Cython\n",
    "# !pip install numpy\n",
    "# !pip install lap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d659ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# esto es para evitar un error en Windows: OMP: Error #15: Initializing libiomp5md.dll, but found libiomp5md.dll already initialized.\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics.nn.autobackend import AutoBackend\n",
    "from ultralytics.yolo.utils.plotting import Annotator, colors\n",
    "import torch\n",
    "from bytetrack.byte_tracker import BYTETracker\n",
    "from ultralytics.yolo.data.dataloaders.stream_loaders import LoadImages\n",
    "from ultralytics.yolo.utils.ops import non_max_suppression, scale_boxes\n",
    "import time\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80a7ae4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3439399",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_thres = 0.25\n",
    "iou_thres = 0.45\n",
    "classes = None\n",
    "agnostic_nms = False\n",
    "max_det = 1000\n",
    "line_thickness = 2\n",
    "half = False\n",
    "imgsz = (1280, 704)\n",
    "vid_stride = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcad7b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_vid = True\n",
    "video_file = \"../../stream_bitrate2.mp4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d71d22f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n"
     ]
    }
   ],
   "source": [
    "# Verificar si CUDA (GPU) está disponible y luego seleccionar el dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Usando dispositivo:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ac7c665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "model = AutoBackend(\"yolov8n.pt\").to(device)\n",
    "model.warmup()\n",
    "stride, names, pt = model.stride, model.names, model.pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69ea3da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bytetracker = BYTETracker(\n",
    "    track_thresh=0.6, match_thresh=0.8, track_buffer=120, frame_rate=30\n",
    ")\n",
    "tracker = bytetracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69b9178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LoadImages(\n",
    "    video_file,\n",
    "    imgsz=imgsz,\n",
    "    stride=stride,\n",
    "    auto=pt,\n",
    "    transforms=None,\n",
    "    vid_stride=vid_stride,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f033a4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "zona_personas = (805, 483, 1101, 618)\n",
    "zona_personas2 = (2, 336, 289, 435)\n",
    "zona_coches = (620, 142, 1149, 428)\n",
    "\n",
    "tiempo_espera_personas = {}\n",
    "tiempo_espera_vehiculos = {}\n",
    "vehiculos = [2, 3, 5, 7] #2: 'car', 3: 'motorcycle', 5: 'bus', 7: 'truck'\n",
    "def interseccion_zona(bbox, zona):\n",
    "    \"\"\" Verifica si la caja delimitadora (bbox) se cruza con la zona definida. \"\"\"\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    zx1, zy1, zx2, zy2 = zona\n",
    "    return not (x2 < zx1 or x1 > zx2 or y2 < zy1 or y1 > zy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dibujar_persona(im0, centro, color):\n",
    "    radio_cabeza = 5\n",
    "    longitud_cuerpo = 8\n",
    "    longitud_brazos = 7\n",
    "    longitud_piernas = 7\n",
    "\n",
    "    centro_cabeza = (centro[0], centro[1] - radio_cabeza - 3)\n",
    "    inicio_cuerpo = (centro[0], centro[1])\n",
    "    fin_cuerpo = (centro[0], centro[1] + longitud_cuerpo)\n",
    "\n",
    "    inicio_brazo_izquierdo = (centro[0], centro[1] + 2)\n",
    "    fin_brazo_izquierdo = (centro[0] - longitud_brazos, centro[1] + 2)\n",
    "    inicio_brazo_derecho = (centro[0], centro[1] + 2)\n",
    "    fin_brazo_derecho = (centro[0] + longitud_brazos, centro[1] + 2)\n",
    "\n",
    "    inicio_pierna_izquierda = (centro[0], centro[1] + longitud_cuerpo)\n",
    "    fin_pierna_izquierda = (centro[0] - longitud_piernas // 2, centro[1] + longitud_cuerpo + longitud_piernas)\n",
    "    inicio_pierna_derecha = (centro[0], centro[1] + longitud_cuerpo)\n",
    "    fin_pierna_derecha = (centro[0] + longitud_piernas // 2, centro[1] + longitud_cuerpo + longitud_piernas)\n",
    "\n",
    "    # Dibuja la cabeza\n",
    "    cv2.circle(im0, centro_cabeza, radio_cabeza, color, -1)\n",
    "\n",
    "    # Dibuja el cuerpo\n",
    "    cv2.line(im0, inicio_cuerpo, fin_cuerpo, color, 2)\n",
    "\n",
    "    # Dibuja los brazos\n",
    "    cv2.line(im0, inicio_brazo_izquierdo, fin_brazo_izquierdo, color, 2)\n",
    "    cv2.line(im0, inicio_brazo_derecho, fin_brazo_derecho, color, 2)\n",
    "\n",
    "    # Dibuja las piernas\n",
    "    cv2.line(im0, inicio_pierna_izquierda, fin_pierna_izquierda, color, 2)\n",
    "    cv2.line(im0, inicio_pierna_derecha, fin_pierna_derecha, color, 2)\n",
    "\n",
    "\n",
    "def dibujar_semaforo(im0, estado_semaforo, estado_semaforo_personas):\n",
    "    alto, ancho = im0.shape[:2]\n",
    "    radio = 15\n",
    "    distancia_entre_luces = 40\n",
    "\n",
    "    # Semáforo para vehículos\n",
    "    x1, y1 = ancho - 120, 20  # Posición del semáforo para vehículos\n",
    "    cv2.rectangle(im0, (x1 - 20, y1 - 20), (x1 + 20, y1 + 3 * distancia_entre_luces), (0, 0, 0), -1)  # Fondo negro\n",
    "    color_rojo = (0, 0, 255) if estado_semaforo == \"Rojo\" else (0, 0, 0)\n",
    "    color_amarillo = (0, 255, 255) if estado_semaforo == \"Amarillo\" else (0, 0, 0)\n",
    "    color_verde = (0, 255, 0) if estado_semaforo == \"Verde\" else (0, 0, 0)\n",
    "    cv2.circle(im0, (x1, y1), radio, color_rojo, -1)\n",
    "    cv2.circle(im0, (x1, y1 + distancia_entre_luces), radio, color_amarillo, -1)\n",
    "    cv2.circle(im0, (x1, y1 + 2 * distancia_entre_luces), radio, color_verde, -1)\n",
    "\n",
    "    # Semáforo para personas\n",
    "    x2, y2 = ancho - 60, 20  # Posición del semáforo para personas\n",
    "    cv2.rectangle(im0, (x2 - 20, y2 - 20), (x2 + 20, y2 + 2 * distancia_entre_luces), (0, 0, 0), -1)  # Fondo negro\n",
    "    color_rojo_personas = (0, 0, 255)\n",
    "    color_verde_personas = (0, 255, 0)\n",
    "    centro_rojo = (x2, y2)\n",
    "    centro_verde = (x2, y2 + distancia_entre_luces)\n",
    "\n",
    "    # Dibuja las luces y las personas\n",
    "    cv2.circle(im0, centro_rojo, radio, color_rojo_personas if estado_semaforo_personas == \"Rojo\" else (0, 0, 0), -1)\n",
    "    cv2.circle(im0, centro_verde, radio, color_verde_personas if estado_semaforo_personas == \"Verde\" else (0, 0, 0), -1)\n",
    "    \n",
    "    # Si la luz está activa, dibuja la persona\n",
    "    if estado_semaforo_personas == \"Rojo\":\n",
    "        dibujar_persona(im0, centro_rojo, (255, 255, 255))  # Dibuja una persona blanca en la luz roja\n",
    "    if estado_semaforo_personas == \"Verde\":\n",
    "        dibujar_persona(im0, centro_verde, (255, 255, 255))  # Dibuja una persona blanca en la luz verde\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f43e5e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContadorSemaforo:\n",
    "    def __init__(self):\n",
    "        self.contador_personas = 0\n",
    "        self.contador_vehiculos = 0\n",
    "        self.tiempo_espera_personas = {}\n",
    "        self.tiempo_espera_vehiculos = {}\n",
    "        self.estado_semaforo = \"Verde\"\n",
    "        self.estado_semaforo_personas = \"Rojo\"\n",
    "        self.umbral_espera_maximo = 60\n",
    "\n",
    "    def asignar_estado_semaforo(self):\n",
    "        tiempo_total_personas = sum(self.tiempo_espera_personas.values())\n",
    "        tiempo_total_vehiculos = sum(self.tiempo_espera_vehiculos.values())\n",
    "        print(\"Tiempo de espera personas\", tiempo_total_personas )\n",
    "        print(\"Tiempo de espera vehiculos\", tiempo_total_vehiculos )\n",
    "\n",
    "        if (\n",
    "            (self.contador_vehiculos > self.contador_personas and tiempo_total_vehiculos > tiempo_total_personas) or\n",
    "            (self.contador_vehiculos < self.contador_personas and tiempo_total_vehiculos > tiempo_total_personas) or\n",
    "            any(tiempo > self.umbral_espera_maximo for tiempo in self.tiempo_espera_vehiculos.values())\n",
    "        ):\n",
    "            self.estado_semaforo = \"Verde\"\n",
    "            self.estado_semaforo_personas = \"Rojo\"\n",
    "        elif (\n",
    "            (self.contador_personas > self.contador_vehiculos and tiempo_total_personas > tiempo_total_vehiculos) or\n",
    "            (self.contador_personas < self.contador_vehiculos and tiempo_total_personas > tiempo_total_vehiculos) or\n",
    "            any(tiempo > self.umbral_espera_maximo for tiempo in self.tiempo_espera_personas.values())\n",
    "        ):\n",
    "            self.estado_semaforo = \"Rojo\"\n",
    "            self.estado_semaforo_personas = \"Verde\"\n",
    "        self.tiempo_espera_personas.clear()\n",
    "        self.tiempo_espera_vehiculos.clear()\n",
    "        return self.estado_semaforo, self.estado_semaforo_personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c8962e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de espera personas 18.044671535491943\n",
      "Tiempo de espera vehiculos 13.317918539047241\n",
      "Tiempo de espera personas 158.2437663078308\n",
      "Tiempo de espera vehiculos 114.31564712524414\n",
      "Tiempo de espera personas 121.62584042549133\n",
      "Tiempo de espera vehiculos 46.41179943084717\n",
      "Tiempo de espera personas 115.7093517780304\n",
      "Tiempo de espera vehiculos 53.90148973464966\n",
      "Tiempo de espera personas 118.20244359970093\n",
      "Tiempo de espera vehiculos 57.74265146255493\n",
      "Tiempo de espera personas 46.814388036727905\n",
      "Tiempo de espera vehiculos 46.21819519996643\n",
      "Tiempo de espera personas 48.26771640777588\n",
      "Tiempo de espera vehiculos 67.37282514572144\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Crear una instancia de la clase ContadorSemaforo\n",
    "contador_semaforo = ContadorSemaforo()\n",
    "\n",
    "estado_semaforo = \"Verde\"\n",
    "estado_semaforo_personas = \"Rojo\"\n",
    "for frame_idx, batch in enumerate(dataset):    \n",
    "    \n",
    "    tiempo_actual = time.time()\n",
    "    path, im, im0s, vid_cap, s = batch\n",
    "    detections = np.empty((0, 5))\n",
    "    # Asegurarse de que los datos de entrada (imágenes) también estén en la GPU\n",
    "    im = torch.from_numpy(im).to(device)\n",
    "    im = im.half() if half else im.float()  # uint8 to fp16/32\n",
    "    im /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "    im = torch.unsqueeze(im, 0)\n",
    "\n",
    "    result = model(im)\n",
    "\n",
    "    p = non_max_suppression(\n",
    "        result, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det\n",
    "    )\n",
    "    contador_personas = 0  # Inicializar el contador de personas en cada frame\n",
    "    contador_vehiculos = 0\n",
    "\n",
    "    for i, det in enumerate(p):\n",
    "        p, im0, _ = path, im0s.copy(), getattr(dataset, \"frame\", 0)\n",
    "\n",
    "        if det is not None and len(det):\n",
    "            det[:, :4] = scale_boxes(\n",
    "                im.shape[2:], det[:, :4], im0.shape\n",
    "            ).round()  # rescale boxes to im0 size\n",
    "\n",
    "        track_result = tracker.update(det.cpu(), im0)\n",
    "\n",
    "        annotator = Annotator(im0, line_width=line_thickness, example=str(names))\n",
    "\n",
    "        # draw boxes for visualization\n",
    "        if len(track_result) > 0:\n",
    "            for j, (output) in enumerate(track_result):\n",
    "                bbox = output[0:4]\n",
    "                id = output[4]\n",
    "                cls = output[5]\n",
    "                conf = output[6]\n",
    "\n",
    "                c = int(cls)  # integer class\n",
    "                id = int(id)  # integer id\n",
    "                \n",
    "                if c == 0 and (interseccion_zona(bbox, zona_personas) or interseccion_zona(bbox, zona_personas2)):\n",
    "                    contador_personas +=1\n",
    "                    contador_semaforo.contador_personas = contador_personas\n",
    "                     # Verificar si el objeto persona está dentro de la zona personas\n",
    "                    if id not in tiempo_espera_personas:\n",
    "                        tiempo_espera_personas[id] = tiempo_actual\n",
    "\n",
    "                    tiempo_deteccion = tiempo_actual - tiempo_espera_personas[id]\n",
    "                    \n",
    "                    contador_semaforo.tiempo_espera_personas[id] = tiempo_deteccion\n",
    "                    \n",
    "                    color_especial = (0, 100, 0) # Color verde fuerte\n",
    "                    \n",
    "                    \n",
    "                elif (c in vehiculos) and interseccion_zona(bbox, zona_coches):\n",
    "                    contador_vehiculos +=1\n",
    "                    contador_semaforo.contador_vehiculos = contador_vehiculos\n",
    "\n",
    "                    if id not in tiempo_espera_vehiculos:\n",
    "                        tiempo_espera_vehiculos[id] = tiempo_actual\n",
    "\n",
    "                    tiempo_deteccion = tiempo_actual - tiempo_espera_vehiculos[id]\n",
    "                    contador_semaforo.tiempo_espera_vehiculos[id] = tiempo_deteccion\n",
    "                    \n",
    "                    color_especial = (0, 0, 255)  \n",
    "                    \n",
    "                else:\n",
    "                    # Si no está dentro de ninguna zona específica, usa el color predeterminado\n",
    "                    if id in tiempo_espera_personas:\n",
    "                        del tiempo_espera_personas[id]\n",
    "                    if id in tiempo_espera_vehiculos:\n",
    "                        del tiempo_espera_vehiculos[id]\n",
    "                    color_especial = colors(c, True)\n",
    "                    tiempo_deteccion = 0\n",
    "                label = f\"{id} {names[c]} {tiempo_deteccion:.2f}s\" \n",
    "                annotator.box_label(bbox, label, color=color_especial)\n",
    "                \n",
    "               \n",
    "    # Visualizar la cantidad de personas y vehículos en la imagen\n",
    "    cv2.putText(im0, f\"Personas: {contador_personas}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0, 255), 2)\n",
    "    cv2.putText(im0, f\"Vehiculos: {contador_vehiculos}\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 2)\n",
    "    dibujar_semaforo(im0, estado_semaforo, estado_semaforo_personas)\n",
    "             \n",
    "    # Stream results\n",
    "    im0 = annotator.result()\n",
    "    cv2.imshow(str(p), im0)\n",
    "    key = cv2.waitKey(20)\n",
    "\n",
    "    if key == 27:  # Presiona 'Esc' para salir\n",
    "        break\n",
    "    elif key == 114 or key == 82:  # Presiona 'R' o 'r' para realizar una acción\n",
    "        estado_semaforo = \"Rojo\"\n",
    "        estado_semaforo_personas = \"Verde\"\n",
    "        pass\n",
    "    elif key == 118 or key == 86:  # Presiona 'V' o 'v' para realizar otra acción\n",
    "        estado_semaforo = \"Verde\"\n",
    "        estado_semaforo_personas = \"Rojo\"\n",
    "        pass\n",
    "    elif key == 113 or key == 81:  # Presiona 'Q' o 'q' para mostrar y cambiar el estado del semáforo\n",
    "        estado_semaforo, estado_semaforo_personas = contador_semaforo.asignar_estado_semaforo()\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0476972",
   "metadata": {},
   "source": [
    "Guardar el video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "312f49c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tiempos_deteccion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mid\u001b[39m)  \u001b[38;5;66;03m# integer id\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m#label = f\"{id} {names[c]} {conf:.2f}\"\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtiempos_deteccion\u001b[49m:\n\u001b[0;32m     51\u001b[0m     tiempos_deteccion[\u001b[38;5;28mid\u001b[39m] \u001b[38;5;241m=\u001b[39m tiempo_actual\n\u001b[0;32m     53\u001b[0m tiempo_deteccion \u001b[38;5;241m=\u001b[39m tiempo_actual \u001b[38;5;241m-\u001b[39m tiempos_deteccion[\u001b[38;5;28mid\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tiempos_deteccion' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "save_vid = True\n",
    "video_file = \"../../stream_bitrate2.mp4\"\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # codec\n",
    "fps = 24  # Asumiendo 30 fps, ajusta según tu video\n",
    "save_path = '../../output.mp4'\n",
    "vid_writer = cv2.VideoWriter(save_path, fourcc, fps, (1280, 704))  # Ajusta la resolución según sea necesario\n",
    "\n",
    "\n",
    "for frame_idx, batch in enumerate(dataset):\n",
    "    tiempo_actual = time.time()\n",
    "    path, im, im0s, vid_cap, s = batch\n",
    "    detections = np.empty((0, 5))\n",
    "    # Asegurarse de que los datos de entrada (imágenes) también estén en la GPU\n",
    "    im = torch.from_numpy(im).to(device)\n",
    "    im = im.half() if half else im.float()  # uint8 to fp16/32\n",
    "    im /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "    im = torch.unsqueeze(im, 0)\n",
    "\n",
    "    result = model(im)\n",
    "\n",
    "    p = non_max_suppression(\n",
    "        result, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det\n",
    "    )\n",
    "\n",
    "    for i, det in enumerate(p):\n",
    "        p, im0, _ = path, im0s.copy(), getattr(dataset, \"frame\", 0)\n",
    "\n",
    "        if det is not None and len(det):\n",
    "            det[:, :4] = scale_boxes(\n",
    "                im.shape[2:], det[:, :4], im0.shape\n",
    "            ).round()  # rescale boxes to im0 size\n",
    "\n",
    "        track_result = tracker.update(det.cpu(), im0)\n",
    "\n",
    "        annotator = Annotator(im0, line_width=line_thickness, example=str(names))\n",
    "\n",
    "        # draw boxes for visualization\n",
    "        if len(track_result) > 0:\n",
    "            for j, (output) in enumerate(track_result):\n",
    "                bbox = output[0:4]\n",
    "                id = output[4]\n",
    "                cls = output[5]\n",
    "                conf = output[6]\n",
    "\n",
    "                c = int(cls)  # integer class\n",
    "                id = int(id)  # integer id\n",
    "                #label = f\"{id} {names[c]} {conf:.2f}\"\n",
    "\n",
    "                if id not in tiempos_deteccion:\n",
    "                    tiempos_deteccion[id] = tiempo_actual\n",
    "\n",
    "                tiempo_deteccion = tiempo_actual - tiempos_deteccion[id]\n",
    "\n",
    "                c = int(cls)  # integer class\n",
    "                label = f\"{id} {names[c]} {tiempo_deteccion:.2f}s\" \n",
    "\n",
    "                if interseccion_zona(bbox, zona_personas):\n",
    "                    color_especial = (0, 255, 0)  # Color verde, por ejemplo\n",
    "                    annotator.box_label(bbox, label, color=color_especial)\n",
    "                else:\n",
    "                    color = colors(c, True)\n",
    "                    annotator.box_label(bbox, label, color=color)\n",
    "\n",
    "                \"\"\" \n",
    "                color = colors(c, True)\n",
    "                annotator.box_label(bbox, label, color=color)\n",
    "                \"\"\"\n",
    "                \n",
    "\n",
    "    # Save results\n",
    "    im0 = annotator.result()\n",
    "    vid_writer.write(im0)\n",
    "\n",
    "\n",
    "\n",
    "vid_writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
